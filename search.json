[{"path":[]},{"path":"http://merliseclyde.github.io/bark/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"interest fostering open welcoming environment, contributors maintainers pledge making participation project community harassment-free experience everyone, regardless age, body size, disability, ethnicity, gender identity expression, level experience, nationality, personal appearance, race, religion, sexual identity orientation.","code":""},{"path":"http://merliseclyde.github.io/bark/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes creating positive environment include: Using welcoming inclusive language respectful differing viewpoints experiences Gracefully accepting constructive criticism Focusing best community Showing empathy towards community members Examples unacceptable behavior participants include: use sexualized language imagery unwelcome sexual attention advances Trolling, insulting/derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical electronic address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"http://merliseclyde.github.io/bark/CODE_OF_CONDUCT.html","id":"our-responsibilities","dir":"","previous_headings":"","what":"Our Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Project maintainers responsible clarifying standards acceptable behavior expected take appropriate fair corrective action response instances unacceptable behavior. Project maintainers right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, ban temporarily permanently contributor behaviors deem inappropriate, threatening, offensive, harmful.","code":""},{"path":"http://merliseclyde.github.io/bark/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within project spaces public spaces individual representing project community. Examples representing project community include using official project e-mail address, posting via official social media account, acting appointed representative online offline event. Representation project may defined clarified project maintainers.","code":""},{"path":"http://merliseclyde.github.io/bark/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported contacting project team clyde@duke.edu. project team review investigate complaints, respond way deems appropriate circumstances. project team obligated maintain confidentiality regard reporter incident. details specific enforcement policies may posted separately. Project maintainers follow enforce Code Conduct good faith may face temporary permanent repercussions determined members project’s leadership.","code":""},{"path":"http://merliseclyde.github.io/bark/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 1.4, available http://contributor-covenant.org/version/1/4","code":""},{"path":"http://merliseclyde.github.io/bark/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to bark development","title":"Contributing to bark development","text":"goal guide help contribute bark. guide divided three main pieces: Filing bug report feature request issue Github. Suggesting change via pull request. Coding Style Guide Contributions bark","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/bark/CONTRIBUTING.html","id":"feature-requests","dir":"","previous_headings":"Issues","what":"Feature Requests","title":"Contributing to bark development","text":"wish easily extract additional information bark objects ? like see new functionality available bark? , feel free fill feature request! Please describe much detail like added. can anything just idea code advanced user!","code":""},{"path":"http://merliseclyde.github.io/bark/CONTRIBUTING.html","id":"bug-reports","dir":"","previous_headings":"Issues","what":"Bug Reports","title":"Contributing to bark development","text":"filing bug report issue, important thing include minimal reproducible example can quickly verify problem, figure fix . three things need include make example reproducible: required packages, data, code. Packages loaded top script, ’s easy see ones example needs. easiest way include data use dput() generate R code recreate . example, recreate mtcars dataset R, ’d perform following steps: Run dput(mtcars) R Copy output reproducible script, type mtcars <- paste. even better can create data.frame() just handful rows columns still illustrates problem. Spend little bit time ensuring code easy others read: make sure ’ve used spaces variable names concise, informative (OK using “.”, camel case “_” variable names improve readibility. details see Style Guide use comments indicate problem lies best remove everything related problem. shorter code , easier understand. can check actually made reproducible example starting fresh R session pasting script . (Unless ’ve specifically asked , please don’t include output sessionInfo().)","code":""},{"path":"http://merliseclyde.github.io/bark/CONTRIBUTING.html","id":"other-issues","dir":"","previous_headings":"Issues","what":"Other issues","title":"Contributing to bark development","text":"sure something bug undocumented feature, see possible errors help files documentation use clarification (issue) please file regular issue","code":""},{"path":"http://merliseclyde.github.io/bark/CONTRIBUTING.html","id":"pull-requests","dir":"","previous_headings":"","what":"Pull requests","title":"Contributing to bark development","text":"contribute change bark, follow steps: Create branch git make changes, ideally using commit -s sign-commits Developer Certificate Origin. Make sure branch passes R CMD check. Push branch github issue pull request (PR). Discuss pull request. Iterate either accept PR decide ’s good fit bark. steps described detail . might feel overwhelming first time get set , gets easier practice. get stuck point, please reach help. ’re familiar git github, please start reading http://r-pkgs..co.nz/git.html Pull requests evaluated following checklist: Motivation. pull request clearly concisely motivates need change. Please describe problem show pull request solves concisely possible. Also include motivation NEWS new release bark comes ’s easy users see ’s changed. Add item top file use markdown formatting. news item end (@yourGithubUsername, #the_issue_number). related changes. submit pull request, please check make sure haven’t accidentally included unrelated changes. make harder see exactly ’s changed, evaluate unexpected side effects. PR corresponds git branch, expect submit multiple changes make sure create multiple branches. multiple changes depend , start first one don’t submit others first one processed. Document ’re adding new parameters new function, ’ll also need document roxygen. Please add short example appropriate function optionally package vignettes. Make sure re-run devtools::document() code submitting. (sure include name authors function!) Testing fixing bug adding new feature, add testthat unit test. seems like lot work don’t worry pull request isn’t perfect. ’s learning process hand help . pull request process, unless ’ve submitted past ’s unlikely pull request accepted . Please don’t submit pull requests change existing behaviour. Instead, think can add new feature minimally invasive way.","code":""},{"path":"http://merliseclyde.github.io/bark/CONTRIBUTING.html","id":"style-guide-for-contributing-to-bark","dir":"","previous_headings":"","what":"Style Guide for Contributing to bark","title":"Contributing to bark development","text":"consistent style improves readibility code. wed particular style generally draw Google Style Guide well Hadley Wickham’s Style Guide noted . Using package styler enforce styling barked TidyVerse helpful, required. Function Variable names: Use informative names using “.”, camel case, “_” improve readibility, .e. variable.name, VariableName variable_name, rather foo xxx. tend avoid _ historical reasons going back S. Assignment: Use either <- = assignment consistent within contribution. many style guides prefer <- suggest using styler enforce use <-, OK = shorter type! Just consistent within contributed code. Spaces: Include spaces around operators =, +, -, <-,  == etc improve readibility. Put space comman, . : :: never spaces around . Additional spaces newlines fine improve readibilty code (e.g. aligmnent arguments). Comments: Comment code whenever can. Explain clear code. Use # start comment followed space capitalize first letter; short inline comments (comments line code) need two spaces # Curly Braces: opening curly brace never go line, closing curly brace go line. exception short conditional statement shuch else code may fit one line. Indentation: Use 2 spaces rather tabs per level indentation. Indent code inside curly braces. Semi-colons: use semi-colons put one statement line. Line Length: Use 80 characters per line code. RStudio setting display vertical line 80 characters visually assist . Turn going Tools -> Global Options… -> Code -> Display -> Show margin File names R code informative end .R. Use - improve readibility. include spaces file names! Contributing adopted ggplot2’s CONTRIBUTING.md","code":""},{"path":"http://merliseclyde.github.io/bark/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"http://merliseclyde.github.io/bark/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/bark/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"http://merliseclyde.github.io/bark/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"http://merliseclyde.github.io/bark/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"http://merliseclyde.github.io/bark/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"http://merliseclyde.github.io/bark/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"http://merliseclyde.github.io/bark/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"http://merliseclyde.github.io/bark/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"http://merliseclyde.github.io/bark/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"http://merliseclyde.github.io/bark/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"http://merliseclyde.github.io/bark/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"http://merliseclyde.github.io/bark/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"http://merliseclyde.github.io/bark/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"http://merliseclyde.github.io/bark/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"http://merliseclyde.github.io/bark/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"http://merliseclyde.github.io/bark/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"http://merliseclyde.github.io/bark/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"http://merliseclyde.github.io/bark/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"http://merliseclyde.github.io/bark/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"http://merliseclyde.github.io/bark/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":[]},{"path":"http://merliseclyde.github.io/bark/SECURITY.html","id":"supported-versions","dir":"","previous_headings":"","what":"Supported Versions","title":"Security Policy","text":"Supported security updates.","code":""},{"path":"http://merliseclyde.github.io/bark/SECURITY.html","id":"reporting-a-vulnerability","dir":"","previous_headings":"","what":"Reporting a Vulnerability","title":"Security Policy","text":"Please submit vulnerability reports Github Issues maintainers address soon possibl","code":""},{"path":"http://merliseclyde.github.io/bark/SECURITY.html","id":"expectations","dir":"","previous_headings":"","what":"Expectations","title":"Security Policy","text":"package utilizes C code efficiency allocates/frees memory. package checked memory leaks prior releases CRAN using ASAN/UBSBAN. package distributed via CRAN https://CRAN.R-project.org/package=bark reports additional checks. development version may installed GitHub https://github.com/merliseclyde/bark checked via github actions (users may check current version passing badge installing) Bugs reported via Issue tracker handled soon possible. (See link )","code":""},{"path":"http://merliseclyde.github.io/bark/SECURITY.html","id":"assurance","dir":"","previous_headings":"","what":"Assurance","title":"Security Policy","text":"highly unlikely malicious code added package. submissions CRAN require verification via maintainer’s email, protected via two factor authentication. pull requests contributions github verified lead maintainer. Based Code Conduct Contributing Guidelines modifications include unit tests cover additional code blocks.","code":""},{"path":"http://merliseclyde.github.io/bark/articles/bark.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"Nonparametric Regression with Bayesian Additive Regression Kernels","text":"get latest version {r bark}, install github (needs compilation))","code":"devtools::install_github(\"merliseclyde/bark\") library(bark)"},{"path":"http://merliseclyde.github.io/bark/articles/bark.html","id":"example","dir":"Articles","previous_headings":"","what":"Example","title":"Nonparametric Regression with Bayesian Additive Regression Kernels","text":"illustrate feature selection simple simulated example Friedman bark similar SVM, however allows different kernel smoothing parameters every dimension inputs \\(x\\) using option common_lambdas = FALSE well selection inputs allowing kernel smoothing parameters zero using option selection = TRUE. plot shows posterior draws \\(\\lambda\\) simulated data two scenarios allowing different \\(\\lambda_d\\) dimension without selection.   plots \\(\\lambda_j\\) without selection (top) selection (bottom) similar, additional shrinkage values towards zero lead improvement RMSE.","code":"set.seed(42) traindata <- data.frame(sim_Friedman2(200, sd=125)) testdata <- data.frame(sim_Friedman2(1000, sd=0)) set.seed(42) fit.bark.d <- bark(y ~ ., data = traindata,                    testdata= testdata,                    classification=FALSE,                     selection = FALSE,                    common_lambdas = FALSE, #                   fixed = list(eps = .25, gam = 2.5),                    nburn = 100,                    nkeep = 250,                    printevery = 10^10)  mean((fit.bark.d$yhat.test.mean-testdata$y)^2) #> [1] 1604.15 set.seed(42) fit.bark.sd <- bark(y ~ ., data=traindata,                     testdata = testdata,                     classification=FALSE,                      selection = TRUE,                     common_lambdas = FALSE,                     fixed = list(eps = .5, gam = 5),                     nburn = 100,                     nkeep = 250,                     printevery = 10^10)  mean((fit.bark.sd$yhat.test.mean-testdata$y)^2) #> [1] 1355.865 boxplot(as.data.frame(fit.bark.d$theta.lambda)) boxplot(as.data.frame(fit.bark.sd$theta.lambda))"},{"path":"http://merliseclyde.github.io/bark/articles/bark.html","id":"comparison","dir":"Articles","previous_headings":"","what":"Comparison","title":"Nonparametric Regression with Bayesian Additive Regression Kernels","text":"compare {r bark} two popular methods, {r BART} {r SVM} provide flexible models also non-linear input variables.","code":"bart.available =  suppressMessages(require(BART)) svm.available  =  suppressMessages(require(e1071)) io.available  =  suppressMessages(require(fdm2id))"},{"path":"http://merliseclyde.github.io/bark/articles/bark.html","id":"svm","dir":"Articles","previous_headings":"Comparison","what":"SVM","title":"Nonparametric Regression with Bayesian Additive Regression Kernels","text":"","code":"if (svm.available) {   friedman2.svm = svm(y ~ ., data=traindata, type=\"eps-regression\")   pred.svm = predict(friedman2.svm, testdata)   mean((pred.svm - testdata$y)^2) } #> [1] 6774.121"},{"path":"http://merliseclyde.github.io/bark/articles/bark.html","id":"bart","dir":"Articles","previous_headings":"Comparison","what":"BART","title":"Nonparametric Regression with Bayesian Additive Regression Kernels","text":"","code":"if (bart.available) {  y.loc = match(\"y\", colnames(traindata))  friedman2.bart = wbart(x.train = as.matrix(traindata[ , -y.loc]),                          y.train =  traindata$y)   pred.bart =   predict(friedman2.bart,                          as.matrix(testdata[ , -y.loc]))   yhat.bart = apply(pred.bart, 2, mean)   mean((yhat.bart - testdata$y)^2) }  #> *****Into main of wbart #> *****Data: #> data:n,p,np: 200, 4, 0 #> y1,yn: -160.199247, -161.188667 #> x1,x[n*p]: 91.480604, 2.404099 #> *****Number of Trees: 200 #> *****Number of Cut Points: 100 ... 100 #> *****burn and ndpost: 100, 1000 #> *****Prior:beta,alpha,tau,nu,lambda: 2.000000,0.950000,33.129480,3.000000,7744.575956 #> *****sigma: 199.394818 #> *****w (weights): 1.000000 ... 1.000000 #> *****Dirichlet:sparse,theta,omega,a,b,rho,augment: 0,0,1,0.5,1,4,0 #> *****nkeeptrain,nkeeptest,nkeeptestme,nkeeptreedraws: 1000,1000,1000,1000 #> *****printevery: 100 #> *****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1 #>  #> MCMC #> done 0 (out of 1100) #> done 100 (out of 1100) #> done 200 (out of 1100) #> done 300 (out of 1100) #> done 400 (out of 1100) #> done 500 (out of 1100) #> done 600 (out of 1100) #> done 700 (out of 1100) #> done 800 (out of 1100) #> done 900 (out of 1100) #> done 1000 (out of 1100) #> time: 3s #> check counts #> trcnt,tecnt,temecnt,treedrawscnt: 1000,0,0,1000 #> *****In main of C++ for bart prediction #> tc (threadcount): 1 #> number of bart draws: 1000 #> number of trees in bart sum: 200 #> number of x columns: 4 #> from x,np,p: 4, 1000 #> ***using serial code #> [1] 4605.555"},{"path":"http://merliseclyde.github.io/bark/articles/bark.html","id":"classification-example","dir":"Articles","previous_headings":"Comparison","what":"Classification Example","title":"Nonparametric Regression with Bayesian Additive Regression Kernels","text":"data generated first 2 dimensions matter  plot shows posterior draws \\(\\lambda\\) simulated data. ## SVM","code":"set.seed(42) n = 500 circle2 = data.frame(sim_circle(n, dim = 5)) train = sample(1:n, size = floor(n/2), rep=FALSE) plot(x.1 ~ x.2, data=circle2, col=y+1) set.seed(42) circle2.bark = bark(y ~ ., data=circle2, subset=train,                     testdata = circle2[-train,],                     classification = TRUE,                     selection = TRUE,                     common_lambdas = FALSE,                     fixed = list(eps = .5, gam = 5),                     nburn = 100,                     nkeep = 250,                     printevery = 10^10) #Classify # mean((circle2.bark$yhat.test.mean > 0) != circle2[-train, \"y\"]) #> [1] 0.02 boxplot(as.data.frame(circle2.bark$theta.lambda)) if (svm.available) {   circle2.svm = svm(y ~ ., data=circle2[train,], type=\"C\")   pred.svm = predict(circle2.svm, circle2[-train,])   mean(pred.svm != circle2[-train, \"y\"]) } #> [1] 0.104 if (bart.available) {   y.loc = match(\"y\", colnames(circle2))   circle.bart = pbart(x.train = as.matrix(circle2[train, -y.loc]),                              y.train =  circle2[train, y.loc])   pred.bart =   predict(circle.bart, as.matrix(circle2[-train, -y.loc]))   mean((pred.bart$prob.test.mean > .5) != circle2[-train, y.loc]) }  #> *****Into main of pbart #> *****Data: #> data:n,p,np: 250, 5, 0 #> y1,yn: 0, 0 #> x1,x[n*p]: -0.791174, 0.207159 #> *****Number of Trees: 50 #> *****Number of Cut Points: 100 ... 100 #> *****burn and ndpost: 100, 1000 #> *****Prior:mybeta,alpha,tau: 2.000000,0.950000,0.212132 #> *****binaryOffset: -0.030084 #> *****Dirichlet:sparse,theta,omega,a,b,rho,augment: 0,0,1,0.5,1,5,0 #> *****nkeeptrain,nkeeptest,nkeeptreedraws: 1000,1000,1000 #> *****printevery: 100 #> *****skiptr,skipte,skiptreedraws: 1,1,1 #>  #> MCMC #> done 0 (out of 1100) #> done 100 (out of 1100) #> done 200 (out of 1100) #> done 300 (out of 1100) #> done 400 (out of 1100) #> done 500 (out of 1100) #> done 600 (out of 1100) #> done 700 (out of 1100) #> done 800 (out of 1100) #> done 900 (out of 1100) #> done 1000 (out of 1100) #> time: 1s #> check counts #> trcnt,tecnt: 1000,0 #> *****In main of C++ for bart prediction #> tc (threadcount): 1 #> number of bart draws: 1000 #> number of trees in bart sum: 50 #> number of x columns: 5 #> from x,np,p: 5, 250 #> ***using serial code #> [1] 0.048"},{"path":"http://merliseclyde.github.io/bark/articles/bark.html","id":"ionosphere-example","dir":"Articles","previous_headings":"","what":"Ionosphere Example","title":"Nonparametric Regression with Bayesian Additive Regression Kernels","text":"","code":"set.seed(42) data(ionosphere, package=\"fdm2id\") y.loc = ncol(ionosphere) ionosphere[, y.loc] = 1L*(ionosphere[, y.loc]  == \"g\") train = sample(nrow(ionosphere), 200, rep=FALSE) io.traindata = ionosphere[train,] io.testdata =  ionosphere[-train,]"},{"path":"http://merliseclyde.github.io/bark/articles/bark.html","id":"bark","dir":"Articles","previous_headings":"Ionosphere Example","what":"BARK","title":"Nonparametric Regression with Bayesian Additive Regression Kernels","text":"","code":"if (io.available) { set.seed(42) io.bark <- bark(V35 ~ ., data= io.traindata,                     testdata = io.testdata,                     classification=TRUE,                      selection = TRUE,                     common_lambdas = FALSE,                     nburn = 100,                     nkeep = 2500,                     keepevery = 100,                     printevery = 10^10) mean((io.bark$yhat.test.mean > 0) != io.testdata[, y.loc]) } #> [1] 0.07284768"},{"path":"http://merliseclyde.github.io/bark/articles/bark.html","id":"bart-1","dir":"Articles","previous_headings":"Ionosphere Example","what":"BART","title":"Nonparametric Regression with Bayesian Additive Regression Kernels","text":"","code":"if (bart.available & io.available) {   io.bart = pbart(x.train = as.matrix(io.traindata[, -y.loc]),                              y.train =  io.traindata[, y.loc]);   pred.bart =   predict(io.bart, io.testdata[, -y.loc]);   mean((pred.bart$prob.test.mean > .5) != io.testdata[, y.loc]) }  #> *****Into main of pbart #> *****Data: #> data:n,p,np: 200, 33, 0 #> y1,yn: 1, 1 #> x1,x[n*p]: 1.000000, 0.045450 #> *****Number of Trees: 50 #> *****Number of Cut Points: 1 ... 100 #> *****burn and ndpost: 100, 1000 #> *****Prior:mybeta,alpha,tau: 2.000000,0.950000,0.212132 #> *****binaryOffset: 0.481727 #> *****Dirichlet:sparse,theta,omega,a,b,rho,augment: 0,0,1,0.5,1,33,0 #> *****nkeeptrain,nkeeptest,nkeeptreedraws: 1000,1000,1000 #> *****printevery: 100 #> *****skiptr,skipte,skiptreedraws: 1,1,1 #>  #> MCMC #> done 0 (out of 1100) #> done 100 (out of 1100) #> done 200 (out of 1100) #> done 300 (out of 1100) #> done 400 (out of 1100) #> done 500 (out of 1100) #> done 600 (out of 1100) #> done 700 (out of 1100) #> done 800 (out of 1100) #> done 900 (out of 1100) #> done 1000 (out of 1100) #> time: 0s #> check counts #> trcnt,tecnt: 1000,0 #> *****In main of C++ for bart prediction #> tc (threadcount): 1 #> number of bart draws: 1000 #> number of trees in bart sum: 50 #> number of x columns: 33 #> from x,np,p: 33, 151 #> ***using serial code #> [1] 0.09933775"},{"path":"http://merliseclyde.github.io/bark/articles/bark.html","id":"svm-1","dir":"Articles","previous_headings":"Ionosphere Example","what":"SVM","title":"Nonparametric Regression with Bayesian Additive Regression Kernels","text":"","code":"if (svm.available & io.available) {   io.svm = svm(V35 ~ ., data=io.traindata, type=\"C\")   pred.svm = predict(io.svm, io.testdata)   mean(pred.svm != io.testdata[, y.loc]) } #> [1] 0.07284768"},{"path":"http://merliseclyde.github.io/bark/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Merlise Clyde. Author, maintainer, thesis advisor.            ORCID=0000-0002-3595-1872 Zhi Ouyang. Author. Robert Wolpert. Contributor, thesis advisor.","code":""},{"path":"http://merliseclyde.github.io/bark/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Clyde M, Ouyang Z (2023). bark: Bayesian Additive Regression Kernels. R package version 1.0.5, https://CRAN.R-project.org/package=bark.","code":"@Manual{,   title = {bark: Bayesian Additive Regression Kernels},   author = {Merlise Clyde and Zhi Ouyang},   year = {2023},   note = {R package version 1.0.5},   url = {https://CRAN.R-project.org/package=bark}, }"},{"path":"http://merliseclyde.github.io/bark/index.html","id":"bark-bayesian-additive-regression-kernels","dir":"","previous_headings":"","what":"Bayesian Additive Regression Kernels","title":"Bayesian Additive Regression Kernels","text":"bark package implements estimation Bayesian nonparametric regression model represented sum multivariate Gaussian kernels flexible model capture nonlinearities, interactions feature selection.","code":""},{"path":"http://merliseclyde.github.io/bark/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Bayesian Additive Regression Kernels","text":"can install released version bark  CRAN : development version GitHub : (verify branch passing R CMD check badge )","code":"install.packages(\"bark\") require(\"devtools\") devtools::install_github(\"merliseclyde/bark\")"},{"path":"http://merliseclyde.github.io/bark/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Bayesian Additive Regression Kernels","text":"bark similar SVM, however allows different kernel smoothing parameters every dimension inputs x well selection inputs allowing kernel smoothing parameters zero. plot shows posterior draws λ simulated data.  posterior distribution λ1 λ4 concentrated near zero, leads x1 x2 dropping mean function.","code":"library(bark) set.seed(42) traindata <- sim_Friedman2(200, sd=125) testdata <- sim_Friedman2(1000, sd=0) fit.bark.d <- bark(y ~ .,                      data=data.frame(traindata),                     testdata = data.frame(testdata),                    classification=FALSE,                     selection = TRUE,                    common_lambdas = FALSE,                    printevery = 10^10)  mean((fit.bark.d$yhat.test.mean-testdata$y)^2) #> [1] 1738.992 boxplot(as.data.frame(fit.bark.d$theta.lambda))"},{"path":"http://merliseclyde.github.io/bark/index.html","id":"roadmap-for-future-enhancements","dir":"","previous_headings":"","what":"Roadmap for Future Enhancements","title":"Bayesian Additive Regression Kernels","text":"next year following enhancements planned: port R code C/C++ improvements speed add S3 methods predict, summary, plot add additional kernels better hyperparameter specification features like see added, please feel free create issue GitHub can discuss!","code":""},{"path":"http://merliseclyde.github.io/bark/reference/bark-deprecated.html","id":null,"dir":"Reference","previous_headings":"","what":"NonParametric Regression using Bayesian Additive Regression Kernels — bark-deprecated","title":"NonParametric Regression using Bayesian Additive Regression Kernels — bark-deprecated","text":"BARK Bayesian sum--kernels model. numeric response \\(y\\), \\(y = f(x) + \\epsilon\\), \\(\\epsilon \\sim N(0,\\sigma^2)\\). binary response \\(y\\), \\(P(Y=1 | x) = F(f(x))\\), \\(F\\) denotes standard normal cdf (probit link).  cases, \\(f\\) sum many Gaussian kernel functions. goal flexible inference unknown function \\(f\\). BARK uses approximation Cauchy process prior distribution unknown function \\(f\\). Feature selection can achieved inference scale parameters Gaussian kernels. BARK accepts four different types prior distributions, e, d, enabling either soft shrinkage  se, sd, enabling hard shrinkage scale parameters.","code":""},{"path":"http://merliseclyde.github.io/bark/reference/bark-deprecated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"NonParametric Regression using Bayesian Additive Regression Kernels — bark-deprecated","text":"x.train Explanatory variables training (sample) data. Must matrix doubles, (usual) rows corresponding observations columns variables. y.train Dependent variable training (sample) data. y numeric continuous response model fit (normal errors). y logical (just values 0 1), binary response model probit link fit. x.test Explanatory variables test (sample) data. structure x.train. type BARK type, e, d, se, sd, default choice se.e: BARK equal weights.d: BARK different weights.se: BARK selection equal weights.sd: BARK selection different weights. classification TRUE/FALSE logical variable, indicating classification regression problem. keepevery Every keepevery draw kept returned user nburn Number MCMC iterations (nburn*keepevery) treated burn . nkeep Number MCMC iterations kept posterior inference. nkeep*keepevery iterations burn . printevery MCMC runs, message printed every printevery draws. keeptrain Logical, whether keep results training samples. fixed list fixed hyperparameters, using default values specified. alpha = 1: stable index, must 1 currently. eps = 0.5: approximation parameter. gam = 5: intensity parameter. la = 1: first argument gamma prior kernel scales. lb = 2: second argument gamma prior kernel scales. pbetaa = 1: first argument beta prior plambda. pbetab = 1: second argument beta prior plambda. n: number training samples, automatically generates. p: number explanatory variables, automatically generates. meanJ: expected number kernels, automatically generates. tune list tuning parameters, expected change. lstep: stepsize lognormal random walk lambda. frequL: frequency update L. dpow: power death step. upow: power update step. varphistep: stepsize lognormal random walk varphi. phistep: stepsize lognormal random walk phi. theta list starting values parameter theta, use defaults nothing given.","code":""},{"path":"http://merliseclyde.github.io/bark/reference/bark-deprecated.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"NonParametric Regression using Bayesian Additive Regression Kernels — bark-deprecated","text":"bark returns list, including: fixed Fixed hyperparameters tune Tuning parameters used theta.last last set parameters posterior draw theta.nvec matrix nrow(x.train)\\(+1\\) rows (nkeep) columns, recording  number kernels training sample theta.varphi matrix nrow(x.train)  \\(+1\\) rows (nkeep) columns,  recording precision normal gamma prior  distribution regression coefficients theta.beta matrix nrow(x.train)\\(+1\\) rows (nkeep) columns,  recording regression coefficients theta.lambda matrix ncol(x.train) rows (nkeep) columns,   recording kernel scale parameters thea.phi vector length nkeep,  recording precision regression Gaussian noise  (1 classification case) yhat.train matrix nrow(x.train) rows (nkeep) columns.  column corresponds draw \\(f^*\\)  posterior \\(f\\)   row corresponds row x.train.  \\((,j)\\) value \\(f^*(x)\\)  \\(j^{th}\\) kept draw \\(f\\)  \\(^{th}\\) row x.train.  classification problems, value  expectation underlying normal  random variable.  Burn-dropped yhat.test yhat.train now x's rows test data yhat.train.mean train data fits = row mean yhat.train yhat.test.mean test data fits = row mean yhat.test","code":""},{"path":"http://merliseclyde.github.io/bark/reference/bark-deprecated.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"NonParametric Regression using Bayesian Additive Regression Kernels — bark-deprecated","text":"BARK implemented using Bayesian MCMC method. MCMC interaction, produce draw joint posterior distribution, .e. full configuration regression coefficients, kernel locations kernel parameters etc. Thus, unlike lot modelling methods R, produce single model object fits summaries may extracted. output consists values \\(f^*(x)\\) (\\(\\sigma^*\\) numeric case) * denotes particular draw. \\(x\\) either row training data (x.train)","code":""},{"path":"http://merliseclyde.github.io/bark/reference/bark-deprecated.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"NonParametric Regression using Bayesian Additive Regression Kernels — bark-deprecated","text":"Ouyang, Zhi (2008) Bayesian Additive Regression Kernels. Duke University. PhD dissertation, page 58.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/bark/reference/bark-deprecated.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"NonParametric Regression using Bayesian Additive Regression Kernels — bark-deprecated","text":"","code":"# Simulate regression example #  Friedman 2 data set, 200 noisy training, 1000 noise free testing #  Out of sample MSE in SVM (default RBF): 6500 (sd. 1600) #  Out of sample MSE in BART (default):    5300 (sd. 1000) traindata <- sim_Friedman2(200, sd=125) testdata <- sim_Friedman2(1000, sd=0) # example with a very small number of iterations to illustrate the method fit.bark.d <- bark_mat(traindata$x, traindata$y, testdata$x,                   nburn=10, nkeep=10, keepevery=10,                   classification=FALSE, type=\"d\") #> [1] \"Starting BARK-d for this regression problem\" boxplot(data.frame(fit.bark.d$theta.lambda))  mean((fit.bark.d$yhat.test.mean-testdata$y)^2) #> [1] 8037.739 # \\donttest{  # Simulate classification example  #  Circle 5 with 2 signals and three noisy dimensions  #  Out of sample erorr rate in SVM (default RBF): 0.110 (sd. 0.02)  #  Out of sample error rate in BART (default):    0.065 (sd. 0.02)  traindata <- sim_circle(200, dim=5)  testdata <- sim_circle(1000, dim=5)  fit.bark.se <- bark_mat(traindata$x, traindata$y, testdata$x, classification=TRUE, type=\"se\") #> [1] \"Starting BARK-se for this classification problem\" #> [1] \"burning iteration 1000, J=11, max(nj)=2\" #> [1] \"burning iteration 2000, J=18, max(nj)=2\" #> [1] \"burning iteration 3000, J=16, max(nj)=2\" #> [1] \"burning iteration 4000, J=14, max(nj)=2\" #> [1] \"burning iteration 5000, J=12, max(nj)=2\" #> [1] \"burning iteration 6000, J=12, max(nj)=2\" #> [1] \"burning iteration 7000, J=12, max(nj)=1\" #> [1] \"burning iteration 8000, J=8, max(nj)=1\" #> [1] \"burning iteration 9000, J=15, max(nj)=1\" #> [1] \"burning iteration 10000, J=12, max(nj)=2\" #> [1] \"posterior mcmc iteration 1000, J=15, max(nj)=1\" #> [1] \"posterior mcmc iteration 2000, J=17, max(nj)=1\" #> [1] \"posterior mcmc iteration 3000, J=18, max(nj)=3\" #> [1] \"posterior mcmc iteration 4000, J=17, max(nj)=2\" #> [1] \"posterior mcmc iteration 5000, J=17, max(nj)=2\" #> [1] \"posterior mcmc iteration 6000, J=17, max(nj)=2\" #> [1] \"posterior mcmc iteration 7000, J=18, max(nj)=2\" #> [1] \"posterior mcmc iteration 8000, J=13, max(nj)=1\" #> [1] \"posterior mcmc iteration 9000, J=15, max(nj)=1\" #> [1] \"posterior mcmc iteration 10000, J=12, max(nj)=1\"  boxplot(data.frame(fit.bark.se$theta.lambda))   mean((fit.bark.se$yhat.test.mean>0)!=testdata$y) #> [1] 0.021 # }"},{"path":"http://merliseclyde.github.io/bark/reference/bark-package-deprecated.html","id":null,"dir":"Reference","previous_headings":"","what":"Deprecated functions in package bark. — bark-package-deprecated","title":"Deprecated functions in package bark. — bark-package-deprecated","text":"functions listed deprecated defunct   near future. possible, alternative functions similar   functionality also mentioned. Help pages deprecated functions   available help(\"<function>-deprecated\").","code":""},{"path":"http://merliseclyde.github.io/bark/reference/bark-package-deprecated.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Deprecated functions in package bark. — bark-package-deprecated","text":"","code":"bark_mat(   x.train,   y.train,   x.test = matrix(0, 0, 0),   type = \"se\",   classification = FALSE,   keepevery = 100,   nburn = 100,   nkeep = 100,   printevery = 1000,   keeptrain = FALSE,   fixed = list(),   tune = list(lstep = 0.5, frequL = 0.2, dpow = 1, upow = 0, varphistep = 0.5, phistep =     1),   theta = list() )  sim.Friedman1(n, sd = 1)  sim.Friedman2(n, sd = 125)  sim.Friedman3(n, sd = 0.1)  sim.Circle(n, dim = 5)"},{"path":"http://merliseclyde.github.io/bark/reference/bark-package-deprecated.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Deprecated functions in package bark. — bark-package-deprecated","text":"List deprecated functions","code":""},{"path":"http://merliseclyde.github.io/bark/reference/bark-package-deprecated.html","id":"bark-mat","dir":"Reference","previous_headings":"","what":"bark_mat","title":"Deprecated functions in package bark. — bark-package-deprecated","text":"Old version matrix inputs used testing;","code":""},{"path":"http://merliseclyde.github.io/bark/reference/bark-package-deprecated.html","id":"sim-friedman-","dir":"Reference","previous_headings":"","what":"sim.Friedman1","title":"Deprecated functions in package bark. — bark-package-deprecated","text":"sim.Friedman1, use sim_Friedman1.","code":""},{"path":"http://merliseclyde.github.io/bark/reference/bark-package-deprecated.html","id":"sim-friedman--1","dir":"Reference","previous_headings":"","what":"sim.Friedman2","title":"Deprecated functions in package bark. — bark-package-deprecated","text":"sim.Friedman2, use sim_Friedman2.","code":""},{"path":"http://merliseclyde.github.io/bark/reference/bark-package-deprecated.html","id":"sim-friedman--2","dir":"Reference","previous_headings":"","what":"sim.Friedman3","title":"Deprecated functions in package bark. — bark-package-deprecated","text":"sim.Friedman3, use sim_Friedman3.","code":""},{"path":"http://merliseclyde.github.io/bark/reference/bark-package-deprecated.html","id":"sim-circle","dir":"Reference","previous_headings":"","what":"sim.Circle","title":"Deprecated functions in package bark. — bark-package-deprecated","text":"sim.Circle, use sim_circle.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/bark/reference/bark-package.html","id":null,"dir":"Reference","previous_headings":"","what":"bark:  Bayesian Additive Regression Trees — bark-package","title":"bark:  Bayesian Additive Regression Trees — bark-package","text":"Implementation Bayesian Additive Regression Kernels  Feature Selection  Nonparametric Regression  Gaussian regression  classification binary Probit models","code":""},{"path":"http://merliseclyde.github.io/bark/reference/bark-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"bark:  Bayesian Additive Regression Trees — bark-package","text":"BARK Bayesian sum--kernels model Bayesian priors Bayesian Additive Regression Kernel model.  numeric response \\(y\\), \\(y = f(x) + \\epsilon\\), \\(\\epsilon \\sim N(0,\\sigma^2)\\). binary response \\(y\\), \\(P(Y=1 | x) = F(f(x))\\), \\(F\\) denotes standard normal cdf (probit link). cases, \\(f\\) sum many Gaussian kernel functions. goal flexible inference unknown function \\(f\\). bark  uses approximated Cauchy process prior distribution unknown function \\(f\\). Feature selection can achieved inference scale parameters Gaussian kernels. BARK accepts four different types prior distributions setting values selection (TRUE FALSE), allows scale parameters variables set zero, removing variables kernels selection = TRUE; enables either soft shrinkage hard  shrinkage scale parameters. input common_lambdas (TRUE FALSE) specifies whether common scale parameter used predictors (TRUE) FALSE allows scale parameters differ across variables kernel.","code":""},{"path":"http://merliseclyde.github.io/bark/reference/bark-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"bark:  Bayesian Additive Regression Trees — bark-package","text":"Ouyang, Zhi (2008) Bayesian Additive Regression Kernels. Duke University. PhD dissertation, Chapter 3.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/bark/reference/bark-package.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"bark:  Bayesian Additive Regression Trees — bark-package","text":"","code":"# \\donttest{  # Simulate regression example  # Friedman 2 data set, 200 noisy training, 1000 noise free testing  # Out of sample MSE in SVM (default RBF): 6500 (sd. 1600)  # Out of sample MSE in BART (default):    5300 (sd. 1000)  traindata <- sim_Friedman2(200, sd=125)  testdata <- sim_Friedman2(1000, sd=0)  fit.bark.d <- bark(y ~ ., data = data.frame(traindata),                     testdata = data.frame(testdata),                      classification = FALSE,                     selection = FALSE,                     common_lambdas = TRUE)  boxplot(as.data.frame(fit.bark.d$theta.lambda))   mean((fit.bark.d$yhat.test.mean-testdata$y)^2) #> [1] 5550.343  # Simulate classification example  # Circle 5 with 2 signals and three noisy dimensions  # Out of sample erorr rate in SVM (default RBF): 0.110 (sd. 0.02)  # Out of sample error rate in BART (default):    0.065 (sd. 0.02)  traindata <- sim_circle(200, dim=5)  testdata <- sim_circle(1000, dim=5)  fit.bark.se <- bark(y ~ ., data= data.frame(traindata),                       testdata= data.frame(testdata),                      classification=TRUE,                       selection=TRUE,                      common_lambdas = FALSE)                      boxplot(as.data.frame(fit.bark.se$theta.lambda))   mean((fit.bark.se$yhat.test.mean>0)!=testdata$y) #> [1] 0.046 # }"},{"path":"http://merliseclyde.github.io/bark/reference/bark.html","id":null,"dir":"Reference","previous_headings":"","what":"Nonparametric Regression using Bayesian Additive Regression Kernels — bark","title":"Nonparametric Regression using Bayesian Additive Regression Kernels — bark","text":"BARK Bayesian sum--kernels model. numeric response \\(y\\), \\(y = f(x) + \\epsilon\\), \\(\\epsilon \\sim N(0,\\sigma^2)\\). binary response \\(y\\), \\(P(Y=1 | x) = F(f(x))\\), \\(F\\) denotes standard normal cdf (probit link).  cases, \\(f\\) sum many Gaussian kernel functions. goal flexible inference unknown function \\(f\\). BARK uses approximation Cauchy process prior distribution unknown function \\(f\\). Feature selection can achieved inference scale parameters Gaussian kernels. BARK accepts four different types prior distributions, e, d, enabling either soft shrinkage  se, sd, enabling hard shrinkage scale parameters.","code":""},{"path":"http://merliseclyde.github.io/bark/reference/bark.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Nonparametric Regression using Bayesian Additive Regression Kernels — bark","text":"","code":"bark(   formula,   data,   subset,   na.action = na.omit,   testdata = NULL,   selection = TRUE,   common_lambdas = TRUE,   classification = FALSE,   keepevery = 100,   nburn = 100,   nkeep = 100,   printevery = 1000,   keeptrain = FALSE,   verbose = FALSE,   fixed = list(),   tune = list(lstep = 0.5, frequL = 0.2, dpow = 1, upow = 0, varphistep = 0.5, phistep =     1),   theta = list() )"},{"path":"http://merliseclyde.github.io/bark/reference/bark.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Nonparametric Regression using Bayesian Additive Regression Kernels — bark","text":"formula model formula model predictors, Y ~ X.  X variables centered scaled part model fitting. data data frame.  Factors converted numerical vectors based using `model.matrix`. subset optional vector specifying subset observations used fitting process. na.action function indicates happen data contain NAs. default \"na.omit\". testdata Dataframe test data sample prediction. structure data. selection Logical variable indicating whether variable  dependent kernel parameters \\(\\lambda\\) may set zero MCMC;  default TRUE. common_lambdas Logical variable indicating whether kernel parameters \\(\\lambda\\) predictor specific common across predictors;  default TRUE.   Note  common_lambdas = TRUE  selection = TRUE applies just non-zero \\(lambda_j\\). classification TRUE/FALSE logical variable, indicating classification regression problem. keepevery Every keepevery draw kept returned user nburn Number MCMC iterations (nburn*keepevery) treated burn . nkeep Number MCMC iterations kept posterior inference. nkeep*keepevery iterations burn . printevery MCMC runs, message printed every printevery draws. keeptrain Logical, whether keep results training samples. verbose Logical, whether print messages fixed list fixed hyperparameters, using default values specified. alpha = 1: stable index, must 1 currently. eps = 0.5: approximation parameter. gam = 5: intensity parameter. la = 1: first argument gamma prior kernel scales. lb = 2: second argument gamma prior kernel scales. pbetaa = 1: first argument beta prior plambda. pbetab = 1: second argument beta prior plambda. n: number training samples, automatically generates. p: number explanatory variables, automatically generates. meanJ: expected number kernels, automatically generates. tune list tuning parameters, expected change. lstep: stepsize lognormal random walk lambda. frequL: frequency update L. dpow: power death step. upow: power update step. varphistep: stepsize lognormal random walk varphi. phistep: stepsize lognormal random walk phi. theta list starting values parameter theta, use defaults nothing given.","code":""},{"path":"http://merliseclyde.github.io/bark/reference/bark.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Nonparametric Regression using Bayesian Additive Regression Kernels — bark","text":"bark returns object class `bark` list, including: call matched call fixed Fixed hyperparameters tune Tuning parameters used theta.last last set parameters posterior draw theta.nvec matrix nrow(x.train)\\(+1\\) rows (nkeep) columns, recording  number kernels training sample theta.varphi matrix nrow(x.train)  \\(+1\\) rows (nkeep) columns,  recording precision normal gamma prior  distribution regression coefficients theta.beta matrix nrow(x.train)\\(+1\\) rows (nkeep) columns,  recording regression coefficients theta.lambda matrix ncol(x.train) rows (nkeep) columns,   recording kernel scale parameters thea.phi vector length nkeep,  recording precision regression Gaussian noise  (1 classification case) yhat.train matrix nrow(x.train) rows (nkeep) columns.  column corresponds draw \\(f^*\\)  posterior \\(f\\)   row corresponds row x.train.  \\((,j)\\) value \\(f^*(x)\\)  \\(j^{th}\\) kept draw \\(f\\)  \\(^{th}\\) row x.train.  classification problems, value  expectation underlying normal  random variable.  Burn-dropped yhat.test yhat.train now x's rows test data;  NULL testdata provided yhat.train.mean train data fits = row mean yhat.train yhat.test.mean test data fits = row mean yhat.test","code":""},{"path":"http://merliseclyde.github.io/bark/reference/bark.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Nonparametric Regression using Bayesian Additive Regression Kernels — bark","text":"BARK implemented using Bayesian MCMC method. MCMC interaction, produce draw joint posterior distribution, .e. full configuration regression coefficients, kernel locations kernel parameters. Thus, unlike lot modelling methods R, produce single model object fits summaries may extracted. output consists values \\(f^*(x)\\) (\\(\\sigma^*\\) numeric case) * denotes particular draw. \\(x\\) either row training data (x.train)","code":""},{"path":"http://merliseclyde.github.io/bark/reference/bark.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Nonparametric Regression using Bayesian Additive Regression Kernels — bark","text":"Ouyang, Zhi (2008) Bayesian Additive Regression Kernels. Duke University. PhD dissertation, page 58.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/bark/reference/bark.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Nonparametric Regression using Bayesian Additive Regression Kernels — bark","text":"","code":"##Simulated regression example # Friedman 2 data set, 200 noisy training, 1000 noise free testing # Out of sample MSE in SVM (default RBF): 6500 (sd. 1600) # Out of sample MSE in BART (default):    5300 (sd. 1000) traindata <- data.frame(sim_Friedman2(200, sd=125)) testdata <- data.frame(sim_Friedman2(1000, sd=0)) # example with a very small number of iterations to illustrate usage fit.bark.d <- bark(y ~ ., data=traindata, testdata= testdata,                    nburn=10, nkeep=10, keepevery=10,                    classification=FALSE,                     common_lambdas = FALSE,                    selection = FALSE) boxplot(data.frame(fit.bark.d$theta.lambda))  mean((fit.bark.d$yhat.test.mean-testdata$y)^2) #> [1] 10654.47 # \\donttest{  ##Simulate classification example  # Circle 5 with 2 signals and three noisy dimensions  # Out of sample erorr rate in SVM (default RBF): 0.110 (sd. 0.02)  # Out of sample error rate in BART (default):    0.065 (sd. 0.02)  traindata <- sim_circle(200, dim=5)  testdata <- sim_circle(1000, dim=5)  fit.bark.se <- bark(y ~ .,                       data=data.frame(traindata),                       testdata= data.frame(testdata),                       classification=TRUE,                      nburn=100, nkeep=200, )  boxplot(as.data.frame(fit.bark.se$theta.lambda))   mean((fit.bark.se$yhat.test.mean>0)!=testdata$y) #> [1] 0.042 # }"},{"path":"http://merliseclyde.github.io/bark/reference/sim.Circle-deprecated.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate Data from Hyper-Sphere for Classification Problems — sim.Circle-deprecated","title":"Simulate Data from Hyper-Sphere for Classification Problems — sim.Circle-deprecated","text":"classification problem Circle described BARK paper (2008). Inputs dim independent variables uniformly distributed interval \\([-1,1]\\), first 2 dim actually signals. Outputs created according formula $$y = 1(x1^2+x2^2 \\le 2/\\pi)$$","code":""},{"path":"http://merliseclyde.github.io/bark/reference/sim.Circle-deprecated.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate Data from Hyper-Sphere for Classification Problems — sim.Circle-deprecated","text":"","code":"sim.Circle(n, dim=5)"},{"path":"http://merliseclyde.github.io/bark/reference/sim.Circle-deprecated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate Data from Hyper-Sphere for Classification Problems — sim.Circle-deprecated","text":"n number data points generate dim number dimension problem, less 2","code":""},{"path":"http://merliseclyde.github.io/bark/reference/sim.Circle-deprecated.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate Data from Hyper-Sphere for Classification Problems — sim.Circle-deprecated","text":"Returns list components x input values (independent variables) y 0/1 output values (dependent variable)","code":""},{"path":"http://merliseclyde.github.io/bark/reference/sim.Circle-deprecated.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulate Data from Hyper-Sphere for Classification Problems — sim.Circle-deprecated","text":"Ouyang, Zhi (2008) Bayesian Additive Regression Kernels. Duke University. PhD dissertation, Chapter 3.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/bark/reference/sim.Circle-deprecated.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate Data from Hyper-Sphere for Classification Problems — sim.Circle-deprecated","text":"","code":"if (FALSE) {   sim.Circle(n=100, dim = 5) }"},{"path":"http://merliseclyde.github.io/bark/reference/sim.Friedman1-deprecated.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated Regression Problem Friedman 1 — sim.Friedman1-deprecated","title":"Simulated Regression Problem Friedman 1 — sim.Friedman1-deprecated","text":"regression problem Friedman 1 described Friedman (1991) Breiman (1996). Inputs 10 independent variables uniformly distributed interval \\([0,1]\\), 5 10 actually used. Outputs created according formula $$y = 10 \\sin(\\pi x1 x2) + 20 (x3 - 0.5)^2 + 10 x4 + 5 x5 + e$$  e \\(N(0,sd^2)\\).","code":""},{"path":"http://merliseclyde.github.io/bark/reference/sim.Friedman1-deprecated.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated Regression Problem Friedman 1 — sim.Friedman1-deprecated","text":"","code":"sim.Friedman1(n, sd=1)"},{"path":"http://merliseclyde.github.io/bark/reference/sim.Friedman1-deprecated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulated Regression Problem Friedman 1 — sim.Friedman1-deprecated","text":"n number data points create sd standard deviation noise, default value 1","code":""},{"path":"http://merliseclyde.github.io/bark/reference/sim.Friedman1-deprecated.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulated Regression Problem Friedman 1 — sim.Friedman1-deprecated","text":"Returns list components x input values (independent variables) y output values (dependent variable)","code":""},{"path":"http://merliseclyde.github.io/bark/reference/sim.Friedman1-deprecated.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulated Regression Problem Friedman 1 — sim.Friedman1-deprecated","text":"Breiman, Leo (1996) Bagging predictors. Machine Learning 24, pages 123-140.  Friedman, Jerome H. (1991) Multivariate adaptive regression splines. Annals Statistics 19 (1), pages 1-67.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/bark/reference/sim.Friedman1-deprecated.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated Regression Problem Friedman 1 — sim.Friedman1-deprecated","text":"","code":"if (FALSE) { sim.Friedman1(100, sd=1) }"},{"path":"http://merliseclyde.github.io/bark/reference/sim.Friedman2-deprecated.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated Regression Problem Friedman 2 — sim.Friedman2-deprecated","title":"Simulated Regression Problem Friedman 2 — sim.Friedman2-deprecated","text":"regression problem Friedman 2 described Friedman (1991) Breiman (1996). Inputs 4 independent variables uniformly distributed ranges $$0 \\le x1 \\le 100$$ $$40 \\pi \\le x2 \\le 560 \\pi$$ $$0 \\le x3 \\le 1$$ $$1 \\le x4 \\le 11$$ outputs created according formula $$y = (x1^2 + (x2 x3 - (1/(x2 x4)))^2)^{0.5} + e$$ e \\(N(0,sd^2)\\).","code":""},{"path":"http://merliseclyde.github.io/bark/reference/sim.Friedman2-deprecated.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated Regression Problem Friedman 2 — sim.Friedman2-deprecated","text":"","code":"sim.Friedman2(n, sd=125)"},{"path":"http://merliseclyde.github.io/bark/reference/sim.Friedman2-deprecated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulated Regression Problem Friedman 2 — sim.Friedman2-deprecated","text":"n number data points create sd Standard deviation noise. default value 125 gives signal noise ratio (.e., ratio standard deviations) 3:1. Thus, variance function (without noise) accounts 90% total variance.","code":""},{"path":"http://merliseclyde.github.io/bark/reference/sim.Friedman2-deprecated.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulated Regression Problem Friedman 2 — sim.Friedman2-deprecated","text":"Returns list components x input values (independent variables) y output values (dependent variable)","code":""},{"path":"http://merliseclyde.github.io/bark/reference/sim.Friedman2-deprecated.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulated Regression Problem Friedman 2 — sim.Friedman2-deprecated","text":"Breiman, Leo (1996) Bagging predictors. Machine Learning 24, pages 123-140.  Friedman, Jerome H. (1991) Multivariate adaptive regression splines. Annals Statistics 19 (1), pages 1-67.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/bark/reference/sim.Friedman2-deprecated.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated Regression Problem Friedman 2 — sim.Friedman2-deprecated","text":"","code":"if (FALSE) { sim.Friedman2(100, sd=125) }"},{"path":"http://merliseclyde.github.io/bark/reference/sim.Friedman3-deprecated.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated Regression Problem Friedman 3 — sim.Friedman3-deprecated","title":"Simulated Regression Problem Friedman 3 — sim.Friedman3-deprecated","text":"regression problem Friedman 3 described Friedman (1991) Breiman (1996). Inputs 4 independent variables uniformly distributed ranges $$0 \\le x1 \\le 100$$ $$40 \\pi \\le x2 \\le 560 \\pi$$ $$0 \\le x3 \\le 1$$ $$1 \\le x4 \\le 11$$ outputs created according formula $$\\mbox{atan}((x2 x3 - (1/(x2 x4)))/x1) + e$$ e \\(N(0,sd^2)\\).","code":""},{"path":"http://merliseclyde.github.io/bark/reference/sim.Friedman3-deprecated.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated Regression Problem Friedman 3 — sim.Friedman3-deprecated","text":"","code":"sim.Friedman3(n, sd=0.1)"},{"path":"http://merliseclyde.github.io/bark/reference/sim.Friedman3-deprecated.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulated Regression Problem Friedman 3 — sim.Friedman3-deprecated","text":"n number data points create sd Standard deviation noise. default value 125 gives signal noise ratio (.e., ratio standard deviations) 3:1. Thus, variance function (without noise) accounts 90% total variance.","code":""},{"path":"http://merliseclyde.github.io/bark/reference/sim.Friedman3-deprecated.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulated Regression Problem Friedman 3 — sim.Friedman3-deprecated","text":"Returns list components x input values (independent variables) y output values (dependent variable)","code":""},{"path":"http://merliseclyde.github.io/bark/reference/sim.Friedman3-deprecated.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulated Regression Problem Friedman 3 — sim.Friedman3-deprecated","text":"Breiman, Leo (1996) Bagging predictors. Machine Learning 24, pages 123-140.  Friedman, Jerome H. (1991) Multivariate adaptive regression splines. Annals Statistics 19 (1), pages 1-67.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/bark/reference/sim.Friedman3-deprecated.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated Regression Problem Friedman 3 — sim.Friedman3-deprecated","text":"","code":"if (FALSE) { sim.Friedman3(n=100, sd=0.1) }"},{"path":"http://merliseclyde.github.io/bark/reference/sim_Friedman1.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated Regression Problem Friedman 1 — sim_Friedman1","title":"Simulated Regression Problem Friedman 1 — sim_Friedman1","text":"regression problem Friedman 1 described Friedman (1991) Breiman (1996). Inputs 10 independent variables uniformly distributed interval \\([0,1]\\), 5 10 actually used. Outputs created according formula $$y = 10 \\sin(\\pi x1 x2) + 20 (x3 - 0.5)^2 + 10 x4 + 5 x5 + e$$  e \\(N(0,sd^2)\\).","code":""},{"path":"http://merliseclyde.github.io/bark/reference/sim_Friedman1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated Regression Problem Friedman 1 — sim_Friedman1","text":"","code":"sim_Friedman1(n, sd = 1)"},{"path":"http://merliseclyde.github.io/bark/reference/sim_Friedman1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulated Regression Problem Friedman 1 — sim_Friedman1","text":"n number data points create sd standard deviation noise, default value 1","code":""},{"path":"http://merliseclyde.github.io/bark/reference/sim_Friedman1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulated Regression Problem Friedman 1 — sim_Friedman1","text":"Returns list components x input values (independent variables) y output values (dependent variable)","code":""},{"path":"http://merliseclyde.github.io/bark/reference/sim_Friedman1.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulated Regression Problem Friedman 1 — sim_Friedman1","text":"Breiman, Leo (1996) Bagging predictors. Machine Learning 24, pages 123-140.  Friedman, Jerome H. (1991) Multivariate adaptive regression splines. Annals Statistics 19 (1), pages 1-67.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/bark/reference/sim_Friedman1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated Regression Problem Friedman 1 — sim_Friedman1","text":"","code":"sim_Friedman1(100, sd=1) #> $x #>               [,1]       [,2]        [,3]       [,4]        [,5]       [,6] #>   [1,] 0.320336813 0.01582500 0.857597875 0.79011767 0.643216915 0.23992959 #>   [2,] 0.120681208 0.70610296 0.793767007 0.68425685 0.587233524 0.86908719 #>   [3,] 0.873295581 0.08631386 0.483261217 0.25579183 0.017790188 0.01670496 #>   [4,] 0.336245005 0.62982403 0.833756755 0.60091030 0.571409370 0.36217008 #>   [5,] 0.543783126 0.15501614 0.395799475 0.81377500 0.991270501 0.56895772 #>   [6,] 0.335396145 0.07242893 0.094102642 0.35045021 0.970418775 0.86058732 #>   [7,] 0.554115426 0.72615371 0.815741687 0.70508095 0.187291156 0.44441380 #>   [8,] 0.230340977 0.79992973 0.902240330 0.04054714 0.837697808 0.53829155 #>   [9,] 0.488207578 0.09976183 0.005848222 0.72420840 0.883114398 0.98445966 #>  [10,] 0.171741976 0.05306183 0.468340087 0.28064939 0.276678551 0.45293042 #>  [11,] 0.682513158 0.52137113 0.371930965 0.02061497 0.353494513 0.18287532 #>  [12,] 0.304061284 0.91559353 0.723670594 0.99221969 0.517028688 0.25473125 #>  [13,] 0.756827246 0.50029349 0.324924449 0.70794804 0.092728535 0.48697252 #>  [14,] 0.111891568 0.89814155 0.075726626 0.09987369 0.959793381 0.52218995 #>  [15,] 0.102507688 0.14733226 0.885215628 0.01895157 0.394438959 0.73020787 #>  [16,] 0.837727351 0.67952182 0.473263680 0.91770488 0.790875110 0.71962143 #>  [17,] 0.820146968 0.02650802 0.556603958 0.34377847 0.327581254 0.53577906 #>  [18,] 0.899759711 0.93382814 0.864527570 0.65626292 0.193832740 0.27301071 #>  [19,] 0.432055827 0.34166249 0.444231791 0.63814751 0.536560006 0.99606502 #>  [20,] 0.376409271 0.26718455 0.070946865 0.14990280 0.072962895 0.57630291 #>  [21,] 0.377996189 0.96557326 0.894190994 0.97992009 0.417230430 0.69748885 #>  [22,] 0.318824483 0.45090489 0.879846679 0.29836887 0.972598960 0.89883271 #>  [23,] 0.164690248 0.31376304 0.342927193 0.58751015 0.003963038 0.94796994 #>  [24,] 0.657731659 0.90897283 0.148963194 0.94191814 0.924364907 0.77918946 #>  [25,] 0.647392320 0.04946572 0.938056350 0.67697806 0.741621449 0.03260203 #>  [26,] 0.062921414 0.27045287 0.986638644 0.52172433 0.986335197 0.71613322 #>  [27,] 0.949274813 0.62764180 0.977073217 0.14530185 0.597736090 0.45485009 #>  [28,] 0.808625304 0.08377499 0.546396979 0.12211916 0.872020365 0.44581729 #>  [29,] 0.937213186 0.70366844 0.711088333 0.75110859 0.931143404 0.67039090 #>  [30,] 0.639899585 0.07375047 0.996850719 0.22500128 0.870950202 0.92060568 #>  [31,] 0.254678141 0.98413673 0.295397643 0.21968836 0.350959804 0.16313073 #>  [32,] 0.926957999 0.72308024 0.453285489 0.05165747 0.782217394 0.45839806 #>  [33,] 0.649159182 0.78229230 0.858213240 0.34944463 0.973659535 0.02040318 #>  [34,] 0.202998552 0.81737830 0.093027736 0.77534040 0.557340962 0.24159815 #>  [35,] 0.024889458 0.48580248 0.503151071 0.37315110 0.144602710 0.25063314 #>  [36,] 0.835286843 0.33755814 0.371258206 0.40299402 0.253336487 0.15365767 #>  [37,] 0.958509567 0.13606496 0.251130878 0.60991658 0.610996539 0.40524620 #>  [38,] 0.597609698 0.95968068 0.821839593 0.35881329 0.834956892 0.31474096 #>  [39,] 0.726669634 0.68787148 0.402318900 0.13791674 0.322623909 0.93248937 #>  [40,] 0.980221662 0.28242987 0.897718877 0.89007434 0.213056391 0.60591069 #>  [41,] 0.422922821 0.16359442 0.797543754 0.86042597 0.375875150 0.24015953 #>  [42,] 0.527220045 0.29545138 0.376225546 0.70329965 0.922415403 0.97411300 #>  [43,] 0.121088526 0.63696732 0.142759702 0.99253038 0.842010179 0.31801320 #>  [44,] 0.466552753 0.58562478 0.063855346 0.92165743 0.553008861 0.85123032 #>  [45,] 0.595243751 0.72571305 0.023344065 0.03040040 0.318013795 0.96805778 #>  [46,] 0.499411681 0.30263053 0.851328264 0.29453369 0.135925154 0.09932991 #>  [47,] 0.152981604 0.18516891 0.720228659 0.88998412 0.954446485 0.09269901 #>  [48,] 0.409658364 0.32444346 0.548408861 0.47094448 0.135507988 0.49085739 #>  [49,] 0.269772003 0.25793943 0.704428770 0.83921602 0.114574570 0.85932144 #>  [50,] 0.837859227 0.95752544 0.562966497 0.04916928 0.802200470 0.34116693 #>  [51,] 0.446231307 0.80982914 0.197036417 0.35109043 0.460391055 0.42652499 #>  [52,] 0.854313634 0.49054488 0.353859189 0.69310168 0.050429760 0.44172688 #>  [53,] 0.997541716 0.89242111 0.798194464 0.09715095 0.537561518 0.11426750 #>  [54,] 0.606741919 0.60890302 0.531575562 0.96744831 0.931985526 0.17302671 #>  [55,] 0.543308009 0.32775633 0.997721014 0.10376164 0.977664569 0.88001468 #>  [56,] 0.772052468 0.17722165 0.550365263 0.06331372 0.946350457 0.37321277 #>  [57,] 0.783273236 0.58383096 0.650475444 0.12406049 0.999980071 0.26285208 #>  [58,] 0.427810432 0.86569970 0.143408469 0.64105134 0.243326688 0.65919020 #>  [59,] 0.102136058 0.12064460 0.924750776 0.14949943 0.910354555 0.17739893 #>  [60,] 0.200315373 0.72036781 0.754158159 0.58764653 0.616356632 0.37655695 #>  [61,] 0.345159536 0.90214977 0.284392373 0.05272736 0.906291401 0.33652104 #>  [62,] 0.024637612 0.69930664 0.274570052 0.47670442 0.474631562 0.25602682 #>  [63,] 0.705059878 0.11249553 0.876850466 0.83813135 0.116648591 0.15706319 #>  [64,] 0.879811590 0.30166022 0.081318013 0.04911983 0.426446540 0.77871128 #>  [65,] 0.203168529 0.24974540 0.390925548 0.16453410 0.526465895 0.02895820 #>  [66,] 0.489166030 0.62028900 0.895756621 0.81929828 0.480685349 0.07844019 #>  [67,] 0.442356062 0.73957386 0.036556153 0.46048613 0.669224191 0.86113393 #>  [68,] 0.659304256 0.01657788 0.520536874 0.80238173 0.584729901 0.97189608 #>  [69,] 0.839719052 0.50115431 0.380881418 0.21830991 0.703571139 0.03692045 #>  [70,] 0.674308322 0.36403325 0.748552978 0.07527890 0.437962151 0.06506470 #>  [71,] 0.444172871 0.68082562 0.811113626 0.36191514 0.473531052 0.85287821 #>  [72,] 0.141326963 0.72969365 0.803530673 0.49421033 0.393095348 0.18562597 #>  [73,] 0.489660565 0.76377647 0.383670413 0.64049116 0.697771817 0.27124660 #>  [74,] 0.510475491 0.79175493 0.738874004 0.39236430 0.453055504 0.04651072 #>  [75,] 0.197001363 0.39990675 0.902659225 0.20419331 0.158365840 0.77150221 #>  [76,] 0.058485288 0.35390859 0.891675719 0.49836258 0.946539409 0.53518233 #>  [77,] 0.843073156 0.52750729 0.644711271 0.70903561 0.761615368 0.42295038 #>  [78,] 0.076661541 0.45595558 0.607317240 0.34304883 0.497995673 0.71494937 #>  [79,] 0.973998145 0.87751925 0.949414706 0.82314464 0.029756662 0.59982542 #>  [80,] 0.273184210 0.18693879 0.814251274 0.06107775 0.215134107 0.08334090 #>  [81,] 0.591899303 0.28360447 0.189652489 0.01148553 0.198152368 0.49842027 #>  [82,] 0.181955078 0.18078672 0.299946913 0.28994726 0.999043406 0.15348275 #>  [83,] 0.606231865 0.98306942 0.746350231 0.59254487 0.688625904 0.31920894 #>  [84,] 0.009013239 0.55931345 0.957167541 0.89966621 0.600228232 0.12453159 #>  [85,] 0.918778774 0.55435309 0.814335059 0.67423365 0.213727555 0.73054175 #>  [86,] 0.097411885 0.75817308 0.472311632 0.60844938 0.263851501 0.01308886 #>  [87,] 0.556010977 0.94253855 0.847753859 0.59664057 0.426975004 0.08145570 #>  [88,] 0.103307501 0.44906339 0.607762643 0.73191554 0.394356234 0.73994113 #>  [89,] 0.265672266 0.18178103 0.028742220 0.84772907 0.259891778 0.76290526 #>  [90,] 0.571739004 0.79268057 0.234203725 0.93299391 0.093834176 0.09115741 #>  [91,] 0.155384762 0.98577309 0.592491397 0.17031357 0.196946536 0.28722958 #>  [92,] 0.341958959 0.12253735 0.328645572 0.36729189 0.397412266 0.87901222 #>  [93,] 0.099243556 0.76430537 0.916814334 0.00149460 0.390795910 0.83494659 #>  [94,] 0.025111045 0.32077397 0.878585991 0.26971471 0.933113499 0.51918118 #>  [95,] 0.827701717 0.42406170 0.443012832 0.84972398 0.238331430 0.87429121 #>  [96,] 0.782961315 0.69914869 0.275799830 0.28270464 0.528342689 0.76721164 #>  [97,] 0.867580219 0.34696407 0.478417214 0.22387097 0.788299042 0.54395559 #>  [98,] 0.321317829 0.20702985 0.918124647 0.57677216 0.101525517 0.07512231 #>  [99,] 0.941235577 0.65842458 0.092992172 0.55825470 0.910632328 0.46369951 #> [100,] 0.330880622 0.93534771 0.106370897 0.60434654 0.091842592 0.18334469 #>              [,7]       [,8]        [,9]       [,10] #>   [1,] 0.37456945 0.47169262 0.500976591 0.650669947 #>   [2,] 0.23623178 0.96420648 0.255194073 0.766199022 #>   [3,] 0.83979268 0.35468199 0.204367048 0.423753402 #>   [4,] 0.52944518 0.48716894 0.790145529 0.631573244 #>   [5,] 0.91810777 0.31971853 0.768451657 0.323876703 #>   [6,] 0.07400012 0.02945321 0.676784347 0.004880776 #>   [7,] 0.27815034 0.61293130 0.480777722 0.257724195 #>   [8,] 0.47849134 0.41502291 0.893499650 0.168424067 #>   [9,] 0.32341112 0.27261973 0.257993470 0.548071311 #>  [10,] 0.46955615 0.62362435 0.080005750 0.730921104 #>  [11,] 0.98020163 0.03196067 0.607434981 0.310136553 #>  [12,] 0.49982774 0.83801160 0.395848215 0.933304868 #>  [13,] 0.07385445 0.25272347 0.955121860 0.161543516 #>  [14,] 0.67507293 0.54935311 0.878326436 0.641689416 #>  [15,] 0.16498222 0.36303523 0.165553320 0.961267703 #>  [16,] 0.47764157 0.98260017 0.193667519 0.040084683 #>  [17,] 0.08682308 0.40508496 0.859938482 0.537593728 #>  [18,] 0.53914787 0.50268748 0.578996949 0.142101873 #>  [19,] 0.11007218 0.55203886 0.524301279 0.239472967 #>  [20,] 0.89972031 0.17652190 0.004501893 0.440875284 #>  [21,] 0.76894088 0.53876162 0.112690431 0.656728184 #>  [22,] 0.53920851 0.61784552 0.414680594 0.201088833 #>  [23,] 0.03340636 0.47000171 0.644197699 0.161770757 #>  [24,] 0.24288954 0.87975530 0.573008075 0.363587835 #>  [25,] 0.54862578 0.45176384 0.389404969 0.972704555 #>  [26,] 0.41273949 0.17002589 0.675672026 0.745851607 #>  [27,] 0.17419844 0.98881141 0.181853628 0.197639915 #>  [28,] 0.25284596 0.44924404 0.251352145 0.063141251 #>  [29,] 0.53571201 0.45247383 0.527874744 0.708823341 #>  [30,] 0.71809279 0.44461077 0.948726464 0.803791354 #>  [31,] 0.55076858 0.53278857 0.966532099 0.076040206 #>  [32,] 0.51279176 0.03867247 0.280720504 0.209779087 #>  [33,] 0.18945310 0.87086281 0.427788994 0.676733822 #>  [34,] 0.11972993 0.01525137 0.762281457 0.637577885 #>  [35,] 0.91931209 0.68672742 0.079882907 0.062825196 #>  [36,] 0.36333443 0.99850672 0.645656071 0.364414589 #>  [37,] 0.32672500 0.82755823 0.436190061 0.225458820 #>  [38,] 0.40753453 0.80645552 0.286001035 0.932614211 #>  [39,] 0.22640717 0.85644604 0.019322290 0.980830455 #>  [40,] 0.75672054 0.28036364 0.877755267 0.057448270 #>  [41,] 0.73668913 0.59614208 0.528188178 0.411039276 #>  [42,] 0.81711540 0.35011870 0.256054888 0.933256731 #>  [43,] 0.55268231 0.49602216 0.235144973 0.726466674 #>  [44,] 0.58922079 0.45858856 0.478100282 0.698866332 #>  [45,] 0.33631392 0.87874584 0.938596642 0.330147956 #>  [46,] 0.98950219 0.62775620 0.835423332 0.771461415 #>  [47,] 0.14861985 0.90075966 0.424898445 0.433633884 #>  [48,] 0.27162427 0.13667758 0.080629477 0.430734076 #>  [49,] 0.53815000 0.21325213 0.239190099 0.533141818 #>  [50,] 0.68809950 0.85315699 0.498626191 0.932066558 #>  [51,] 0.08415293 0.26974158 0.044291027 0.097181087 #>  [52,] 0.63779066 0.41556852 0.394851753 0.599551111 #>  [53,] 0.24111568 0.11130178 0.098960944 0.091466339 #>  [54,] 0.30449873 0.23562401 0.903917335 0.607121894 #>  [55,] 0.18915699 0.31373039 0.802269486 0.677637859 #>  [56,] 0.32548650 0.86540999 0.734736711 0.956911474 #>  [57,] 0.43512818 0.99738890 0.659973927 0.616047502 #>  [58,] 0.96743751 0.25238162 0.663690983 0.605955217 #>  [59,] 0.73392873 0.21567317 0.600858484 0.052198306 #>  [60,] 0.31361614 0.02623030 0.149262469 0.354092370 #>  [61,] 0.60868427 0.16492983 0.782875039 0.571182048 #>  [62,] 0.69230003 0.45701079 0.299914105 0.589948745 #>  [63,] 0.30675573 0.39401861 0.555600126 0.848042199 #>  [64,] 0.63702726 0.35141591 0.688078111 0.068679139 #>  [65,] 0.79266001 0.07287274 0.304392040 0.372921761 #>  [66,] 0.48992910 0.06154503 0.405528721 0.661446465 #>  [67,] 0.31967919 0.83674688 0.314821050 0.765814023 #>  [68,] 0.69544544 0.21742556 0.909208134 0.107883561 #>  [69,] 0.40670954 0.31864756 0.856032606 0.624455608 #>  [70,] 0.76564147 0.23069328 0.080527651 0.680617578 #>  [71,] 0.10781428 0.61654783 0.169915702 0.467889101 #>  [72,] 0.17722643 0.87221133 0.643596732 0.230551696 #>  [73,] 0.15032595 0.24900341 0.675160205 0.375390142 #>  [74,] 0.21269033 0.48776220 0.462398083 0.822107081 #>  [75,] 0.19939174 0.41688560 0.734425902 0.028093205 #>  [76,] 0.47471633 0.34787723 0.675273370 0.764148453 #>  [77,] 0.36457383 0.54421320 0.168912238 0.212572982 #>  [78,] 0.41527814 0.98786389 0.597002785 0.811361694 #>  [79,] 0.10801282 0.98829784 0.199050241 0.212946411 #>  [80,] 0.42048584 0.47197158 0.709872801 0.916239712 #>  [81,] 0.31900660 0.10799851 0.977857600 0.530737458 #>  [82,] 0.04565747 0.47038706 0.011986982 0.081573146 #>  [83,] 0.27203484 0.06721173 0.499988751 0.658872952 #>  [84,] 0.85781303 0.49114763 0.198862191 0.733621144 #>  [85,] 0.52175437 0.64600302 0.381366286 0.141160326 #>  [86,] 0.61908479 0.17714660 0.714373596 0.405486281 #>  [87,] 0.86661331 0.24872867 0.233494798 0.635854726 #>  [88,] 0.21661850 0.28082471 0.444028166 0.951882908 #>  [89,] 0.78482082 0.86971979 0.182966928 0.860754731 #>  [90,] 0.23840514 0.48131820 0.814597824 0.597386512 #>  [91,] 0.07989419 0.82502904 0.991179598 0.119275906 #>  [92,] 0.91541515 0.82789794 0.825395232 0.250148918 #>  [93,] 0.83541774 0.03716169 0.503876098 0.890107831 #>  [94,] 0.28343083 0.56688890 0.893607481 0.907389605 #>  [95,] 0.23867089 0.89996362 0.541649321 0.680642556 #>  [96,] 0.71352961 0.04626770 0.338465678 0.625894442 #>  [97,] 0.60909164 0.86523962 0.056852846 0.204943084 #>  [98,] 0.40457523 0.35401909 0.441365463 0.432385588 #>  [99,] 0.15654050 0.39549565 0.049184157 0.756730889 #> [100,] 0.49929369 0.55220103 0.491280468 0.609508889 #>  #> $y #>   [1] 16.531483 16.733758  5.530614 21.626746 21.030256 16.796782 22.069718 #>   [8] 18.527024 21.968224  6.869170 12.300906 21.979783 17.726525 16.196784 #>  [15]  7.315153 26.896624  6.964915 15.193731 15.843656  9.574668 25.395418 #>  [22] 18.670334  9.258779 29.436131 19.528233 20.280070 20.307399 12.224906 #>  [29] 26.794929 18.566975 12.911562 17.657799 25.176959 21.646954  8.235607 #>  [36] 13.179895 17.231961 24.089281 17.246185 21.675085 15.967601 22.134714 #>  [43] 23.896046 25.579008 18.143748  9.794401 19.722731  8.658684 12.531100 #>  [50] 14.518523 18.234582 18.661380 13.084554 29.643182 21.334651 13.722204 #>  [57] 22.277960 20.339654 15.613759 17.646018 18.828612 11.405015 16.730936 #>  [64] 15.788377  9.795504 22.978723 23.967036 15.374298 20.326334 13.410895 #>  [71] 18.992584 13.554723 21.645855 17.811189 10.169153 19.120940 25.576464 #>  [78]  8.114838 17.628777  6.202705 11.196219 13.002212 24.662133 19.662551 #>  [85] 20.583552 11.358980 23.554274 13.097859 16.771608 21.582919  9.440422 #>  [92] 10.092450 10.417039 15.659440 19.380623 19.887544 18.145647 12.715241 #>  [99] 26.224556 20.387085 #>"},{"path":"http://merliseclyde.github.io/bark/reference/sim_Friedman2.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated Regression Problem Friedman 2 — sim_Friedman2","title":"Simulated Regression Problem Friedman 2 — sim_Friedman2","text":"regression problem Friedman 2 described Friedman (1991) Breiman (1996). Inputs 4 independent variables uniformly distributed ranges $$0 \\le x1 \\le 100$$ $$40 \\pi \\le x2 \\le 560 \\pi$$ $$0 \\le x3 \\le 1$$ $$1 \\le x4 \\le 11$$ outputs created according formula $$y = (x1^2 + (x2 x3 - (1/(x2 x4)))^2)^{0.5} + e$$ e \\(N(0,sd^2)\\).","code":""},{"path":"http://merliseclyde.github.io/bark/reference/sim_Friedman2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated Regression Problem Friedman 2 — sim_Friedman2","text":"","code":"sim_Friedman2(n, sd = 125)"},{"path":"http://merliseclyde.github.io/bark/reference/sim_Friedman2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulated Regression Problem Friedman 2 — sim_Friedman2","text":"n number data points create sd Standard deviation noise. default value 125 gives signal noise ratio (.e., ratio standard deviations) 3:1. Thus, variance function (without noise) accounts 90% total variance.","code":""},{"path":"http://merliseclyde.github.io/bark/reference/sim_Friedman2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulated Regression Problem Friedman 2 — sim_Friedman2","text":"Returns list components x input values (independent variables) y output values (dependent variable)","code":""},{"path":"http://merliseclyde.github.io/bark/reference/sim_Friedman2.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulated Regression Problem Friedman 2 — sim_Friedman2","text":"Breiman, Leo (1996) Bagging predictors. Machine Learning 24, pages 123-140.  Friedman, Jerome H. (1991) Multivariate adaptive regression splines. Annals Statistics 19 (1), pages 1-67.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/bark/reference/sim_Friedman2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated Regression Problem Friedman 2 — sim_Friedman2","text":"","code":"sim_Friedman2(100, sd=125) #> $x #>              [,1]      [,2]       [,3]      [,4] #>   [1,] 85.5712226  548.8811 0.78272192  6.435557 #>   [2,] 82.9117976  217.0881 0.65256878  5.843171 #>   [3,]  7.6636695 1668.5261 0.40381177  9.058444 #>   [4,] 27.1326610 1247.6416 0.82781869  9.433525 #>   [5,] 93.0935478 1719.9982 0.33234638  6.986745 #>   [6,] 95.6758956 1371.8689 0.87467123  1.016871 #>   [7,] 96.1990635  161.0878 0.68213562  1.098711 #>   [8,]  0.9357188 1013.1668 0.13885895  7.344688 #>   [9,] 13.1667833 1502.6833 0.58216604  9.467200 #>  [10,]  0.7326303  795.7202 0.79939704  1.951869 #>  [11,] 22.1103892  974.0956 0.07810048 10.796378 #>  [12,] 64.8484738  468.7898 0.41725975  3.795120 #>  [13,] 28.6075152  684.5498 0.42188606  9.701177 #>  [14,] 76.1010452  800.3742 0.49660236  7.043988 #>  [15,] 64.4081934 1676.0610 0.43366435  7.639844 #>  [16,] 76.0012381  356.2813 0.67820641  9.491437 #>  [17,] 76.6410058  734.3730 0.15645723 10.272365 #>  [18,] 61.8688589 1557.4681 0.17427363  6.513711 #>  [19,] 67.3950463 1533.4952 0.43746017  9.670470 #>  [20,] 90.4057587 1197.7811 0.16930268  8.875571 #>  [21,] 86.1198180  685.7312 0.33084158  5.848165 #>  [22,] 49.0224186  961.4272 0.28979849  4.282391 #>  [23,] 21.0286639  778.7854 0.04235193  7.589662 #>  [24,] 70.1121365 1186.2984 0.80473355  2.929704 #>  [25,] 74.5378236 1517.6436 0.50082299  6.421030 #>  [26,]  7.0765538  441.7872 0.05262719  4.398189 #>  [27,] 13.5167693 1010.2227 0.56123656  9.689315 #>  [28,] 10.3427712  317.8800 0.95721899 10.871261 #>  [29,] 46.6803694  379.7695 0.11556762  6.918876 #>  [30,] 14.0220642  887.8183 0.95945688  6.464467 #>  [31,] 34.6718231 1187.7861 0.83993241  9.163469 #>  [32,] 46.3078131 1677.4016 0.79625032  1.237695 #>  [33,] 10.1286775  181.8756 0.06635105  7.059348 #>  [34,] 79.0757417  624.3515 0.75364824  5.470300 #>  [35,] 44.4014639  825.7324 0.28046808  3.607667 #>  [36,] 71.1056315  677.4707 0.38931981  7.925521 #>  [37,] 35.6561532  629.9972 0.64854522  2.776191 #>  [38,] 79.9664036  870.8002 0.36239362  6.519167 #>  [39,] 84.7560775  892.1857 0.97358013  5.755540 #>  [40,] 49.9883001  584.4299 0.63447992  7.050490 #>  [41,] 12.7353444  530.1272 0.54461160  2.514132 #>  [42,]  8.2715650  688.5821 0.10556410 10.059179 #>  [43,] 31.3352777  320.9938 0.43295244  3.652667 #>  [44,] 92.1480857 1511.8964 0.36118819  6.020114 #>  [45,] 97.2011456 1105.2278 0.52058900  5.114867 #>  [46,] 55.8723168 1224.5699 0.18785423  7.021137 #>  [47,] 40.5674203 1497.6213 0.20390480  2.530185 #>  [48,] 42.1481643 1537.1130 0.34691023  1.635265 #>  [49,] 80.1252087  361.5089 0.94953946  3.881933 #>  [50,]  4.6183163 1158.3367 0.77127472  7.070442 #>  [51,] 90.4713320 1526.8792 0.36713324  5.019848 #>  [52,]  3.2906803  940.3445 0.68911647  7.436176 #>  [53,] 99.0764543  964.7739 0.79396913  6.749402 #>  [54,] 98.3423803 1565.1752 0.19247257  3.205168 #>  [55,] 59.2271683 1396.1563 0.33402803 10.456925 #>  [56,] 97.5053345  343.7934 0.37294242  1.203878 #>  [57,] 24.2113423  151.2362 0.14759799  2.245629 #>  [58,] 75.7611526  975.9315 0.21115782  3.658860 #>  [59,] 22.6158252  828.2498 0.45330092  3.560619 #>  [60,] 55.8331395 1271.2136 0.26427527  8.370868 #>  [61,] 85.3930002  829.8446 0.31725951  1.845856 #>  [62,] 43.1751407  634.7913 0.42394100  5.733214 #>  [63,] 12.3954856  914.6904 0.98931762 10.809869 #>  [64,] 48.1691671  516.8179 0.34932324  6.440445 #>  [65,] 79.8302766  516.8661 0.04906451  9.069533 #>  [66,] 93.1476542  810.2009 0.98244107 10.565232 #>  [67,] 94.6542374  880.0185 0.61509306  1.986621 #>  [68,] 69.9105676 1566.8904 0.47946256  6.173291 #>  [69,] 30.9386709  369.4811 0.18446311 10.411658 #>  [70,] 21.1138177 1701.1251 0.75670680  3.091592 #>  [71,] 81.9428563 1040.4243 0.96184603  4.786711 #>  [72,] 36.3998384 1536.6795 0.44354730 10.494578 #>  [73,] 56.7496140 1730.2929 0.74441022  3.686216 #>  [74,] 75.1508991  705.0194 0.36111357  9.913884 #>  [75,] 65.5035716  629.8362 0.56432647  4.632786 #>  [76,] 15.8586491  708.1754 0.48633246  3.433311 #>  [77,] 24.0610821  863.5648 0.89563983  1.978084 #>  [78,]  2.6600578 1035.3391 0.26474021  9.749863 #>  [79,] 33.0578959  420.9452 0.61810162  2.064266 #>  [80,]  7.8523319 1106.7312 0.57723736  8.447464 #>  [81,]  1.8877773  209.9294 0.08397875  5.195828 #>  [82,] 40.1631122  274.1553 0.28962410  9.896640 #>  [83,] 79.8509840 1545.3724 0.55597503  8.185164 #>  [84,] 32.3156470 1385.2006 0.58580879  9.720034 #>  [85,] 10.2681812  170.3593 0.82319223  2.787664 #>  [86,] 81.9088813  548.3792 0.50367129  8.904293 #>  [87,] 65.4518663 1030.5891 0.89690155  8.845353 #>  [88,] 47.5488939 1750.8202 0.07370826  7.263593 #>  [89,] 74.7140920 1618.6938 0.37439787  5.632115 #>  [90,] 54.4996286  989.4982 0.31364983  3.576212 #>  [91,] 13.8108258  957.3804 0.08537703  5.945574 #>  [92,] 46.3226606  566.1514 0.90712398  9.200489 #>  [93,] 18.5880699 1676.9743 0.88384417  2.028662 #>  [94,] 28.7474693  322.4265 0.09748382  8.958387 #>  [95,] 51.0160616  999.8459 0.86670068  8.052070 #>  [96,] 77.9340403  189.3422 0.84460427  9.961598 #>  [97,]  1.7927497  187.8072 0.04042689  6.726817 #>  [98,] 79.9483848 1388.9711 0.45274806  1.569268 #>  [99,] 87.8379328 1114.9143 0.60794840  2.592905 #> [100,] 46.0814536 1123.7775 0.82838556  7.614937 #>  #> $y #>   [1]  596.9418759  228.1957037  638.4852826 1143.2173100  805.8835140 #>   [6] 1094.1563151  203.5558641   58.8237803  771.1005228  756.2722903 #>  [11]  327.7001131  192.0027808  400.2734411  363.5077123  851.5493870 #>  [16]  111.1193826  -28.5466301  478.0357228  702.1720184   55.2080197 #>  [21]   16.2418455  316.8368615    0.1824025  825.4828463  706.5230752 #>  [26]    5.9475851  734.7401875  252.3729106    4.4729976  631.7117057 #>  [31]  927.7401859 1321.0911073   70.6473851  507.7615892  106.2093326 #>  [36]  226.8120787  501.4697413  386.0205978  861.1989791  614.7399158 #>  [41]  209.7992026  106.1184387   47.1366445  484.3736810  557.1458322 #>  [46]  240.0455790  389.0247553  762.3347105  278.1607209  750.2346949 #>  [51]  890.1818290  375.4200799 1073.9131406  402.6060864  623.6853516 #>  [56]   24.5913239   42.1912712  120.5324969  489.9610258  452.0682728 #>  [61]  229.2452580   61.7297954  913.2948728  302.0210415  143.5863037 #>  [66]  808.6818206  618.9409230  937.3844579  133.1600702 1138.7005286 #>  [71] 1089.5201718  619.2889289 1506.9124320  376.2251668  520.7377569 #>  [76]  393.3678357  815.6051214  265.3332395  116.1879952  582.5535805 #>  [81]   18.4878580  144.7705516  789.7879185  733.2930864  258.2716463 #>  [86]  164.3697739  927.7020009  442.9507626  433.8298195  667.2542211 #>  [91]  167.2150959  474.6628948 1613.1575564  178.3044787  930.7938258 #>  [96]  319.5839641  157.7909209  533.2928576  644.4237612  845.7081443 #>"},{"path":"http://merliseclyde.github.io/bark/reference/sim_Friedman3.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated Regression Problem Friedman 3 — sim_Friedman3","title":"Simulated Regression Problem Friedman 3 — sim_Friedman3","text":"regression problem Friedman 3 described Friedman (1991) Breiman (1996). Inputs 4 independent variables uniformly distributed ranges $$0 \\le x1 \\le 100$$ $$40 \\pi \\le x2 \\le 560 \\pi$$ $$0 \\le x3 \\le 1$$ $$1 \\le x4 \\le 11$$ outputs created according formula $$\\mbox{atan}((x2 x3 - (1/(x2 x4)))/x1) + e$$ e \\(N(0,sd^2)\\).","code":""},{"path":"http://merliseclyde.github.io/bark/reference/sim_Friedman3.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated Regression Problem Friedman 3 — sim_Friedman3","text":"","code":"sim_Friedman3(n, sd = 0.1)"},{"path":"http://merliseclyde.github.io/bark/reference/sim_Friedman3.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulated Regression Problem Friedman 3 — sim_Friedman3","text":"n number data points create sd Standard deviation noise. default value 125 gives signal noise ratio (.e., ratio standard deviations) 3:1. Thus, variance function (without noise) accounts 90% total variance.","code":""},{"path":"http://merliseclyde.github.io/bark/reference/sim_Friedman3.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulated Regression Problem Friedman 3 — sim_Friedman3","text":"Returns list components x input values (independent variables) y output values (dependent variable)","code":""},{"path":"http://merliseclyde.github.io/bark/reference/sim_Friedman3.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulated Regression Problem Friedman 3 — sim_Friedman3","text":"Breiman, Leo (1996) Bagging predictors. Machine Learning 24, pages 123-140.  Friedman, Jerome H. (1991) Multivariate adaptive regression splines. Annals Statistics 19 (1), pages 1-67.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/bark/reference/sim_Friedman3.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated Regression Problem Friedman 3 — sim_Friedman3","text":"","code":"sim_Friedman3(n=100, sd=0.1) #> $x #>             [,1]      [,2]        [,3]      [,4] #>   [1,] 32.768814  483.7551 0.997378275  3.577079 #>   [2,] 48.503046 1142.2918 0.036128656 10.296956 #>   [3,] 55.490014  992.9479 0.513775065  5.493931 #>   [4,] 40.005154 1728.6739 0.335343137  8.438747 #>   [5,] 91.134663  368.0581 0.119669283  4.321446 #>   [6,] 73.283574  254.2703 0.996547172 10.766577 #>   [7,] 29.151644 1299.4459 0.798869229  3.047162 #>   [8,] 99.974578  542.6114 0.074213889  2.600134 #>   [9,] 35.880376  468.9100 0.417934912  7.948420 #>  [10,] 22.696822 1184.9141 0.520830153  9.378219 #>  [11,] 38.448136 1503.4862 0.833951416  6.548293 #>  [12,] 84.836943 1139.0463 0.095918219  5.315139 #>  [13,] 64.230253  887.8280 0.130021954  2.131398 #>  [14,] 33.136280 1491.8375 0.994169818  2.048606 #>  [15,] 54.871420  874.8872 0.708694441  7.016893 #>  [16,]  7.506210 1681.0586 0.774018628  2.849307 #>  [17,] 81.773981  126.2840 0.426373217  3.095798 #>  [18,] 40.992105  776.6508 0.458778480  2.559382 #>  [19,] 51.888951 1055.9274 0.507226409  2.148856 #>  [20,] 39.927512 1639.4709 0.802135614  8.384202 #>  [21,] 34.107991  139.1769 0.242674659  8.541427 #>  [22,] 31.530688  602.1237 0.885295354  7.690355 #>  [23,] 50.991164 1040.5384 0.994331382  2.488285 #>  [24,] 68.616764  912.8162 0.918956650  8.048023 #>  [25,] 69.015892  895.6988 0.312627782 10.756583 #>  [26,] 92.470232 1388.3211 0.528121571  5.273265 #>  [27,] 34.586118 1702.0900 0.165932779  1.767747 #>  [28,] 13.724943  461.6237 0.276426475  1.169443 #>  [29,] 90.678474 1237.9875 0.658181264  2.343739 #>  [30,]  4.985430  936.2019 0.934001420  7.695812 #>  [31,] 16.270332  427.8360 0.341341716  2.565080 #>  [32,] 16.624611 1327.6516 0.513558489  5.590853 #>  [33,] 38.514040 1249.0065 0.744687303  9.151153 #>  [34,] 49.379416  286.8028 0.015133403  5.634689 #>  [35,] 42.379807  297.3362 0.337359303  4.496896 #>  [36,] 73.623214  174.6103 0.698730376  6.640928 #>  [37,] 85.628617  729.1820 0.300432188  5.671029 #>  [38,] 83.044189  969.7218 0.433478193  8.047341 #>  [39,]  2.307317 1730.9443 0.508572658  9.663477 #>  [40,] 61.691968  414.7032 0.359311635  2.472004 #>  [41,]  8.872046  172.2465 0.598679971  3.363222 #>  [42,] 78.621380 1573.8031 0.270918028  9.179958 #>  [43,] 64.308173  643.4165 0.134041122  6.399326 #>  [44,] 48.931867  903.6682 0.961776408  1.329399 #>  [45,] 99.110414 1147.5962 0.575076373  1.339066 #>  [46,] 83.153728  496.6635 0.834604850  8.114461 #>  [47,] 38.560359  488.0679 0.428683551  1.030475 #>  [48,] 77.629258  146.2339 0.569875540  6.185043 #>  [49,] 62.286888 1137.1734 0.778758455  3.179188 #>  [50,] 67.016663  445.4314 0.099535167 10.398779 #>  [51,] 62.084254  446.6123 0.313777262  5.716767 #>  [52,] 11.381047  271.8270 0.886505685  6.726685 #>  [53,] 87.034918 1393.1192 0.492535823  7.657998 #>  [54,] 96.498692 1595.3255 0.497124110  9.411432 #>  [55,] 71.335442  482.6714 0.700426692  2.584829 #>  [56,] 84.879721  733.8890 0.836857292  9.425367 #>  [57,] 15.835122  257.7057 0.394260472  7.134717 #>  [58,] 75.866474 1399.0531 0.230091893 10.360072 #>  [59,] 99.614002 1177.5008 0.715252058  2.719882 #>  [60,] 80.497161 1360.7533 0.672716324  1.786299 #>  [61,] 30.658886 1091.1682 0.964070297  6.642619 #>  [62,] 69.232251  525.3963 0.657280839  9.016866 #>  [63,] 32.132570  514.6521 0.634049006  9.463678 #>  [64,] 80.235539 1667.0456 0.655284028  4.455309 #>  [65,] 86.250516  270.6084 0.240471442  8.975557 #>  [66,] 24.288563 1065.9997 0.119865755  1.611145 #>  [67,] 76.007930  746.0888 0.151241126  8.742380 #>  [68,] 34.424514  903.9730 0.304172860  5.644006 #>  [69,] 60.551478 1515.2705 0.720566187  6.758828 #>  [70,] 12.539685 1554.8084 0.516003758  2.677523 #>  [71,] 79.410742  853.8767 0.471895436  1.781831 #>  [72,] 37.629662 1143.1817 0.476310359  1.045329 #>  [73,] 41.993204  254.0711 0.771543544  4.060086 #>  [74,] 32.626748  886.4678 0.114836879  6.076712 #>  [75,] 21.529919  720.1743 0.606527464  4.226861 #>  [76,] 65.738203 1114.8453 0.196060520  6.084772 #>  [77,] 44.940651 1110.4598 0.043527182  6.171819 #>  [78,] 45.347809  201.1013 0.522484242 10.049677 #>  [79,] 58.123554 1114.2074 0.642733385  2.364970 #>  [80,] 62.805517 1259.6647 0.270725609  2.458608 #>  [81,] 18.192414 1688.9356 0.962521865  4.225573 #>  [82,] 65.768172  976.5855 0.005580495  8.339858 #>  [83,]  4.824224 1054.4268 0.793081484  7.734118 #>  [84,] 34.147062  329.4671 0.524352187  3.630168 #>  [85,] 33.623280 1128.6737 0.290306708  9.764653 #>  [86,] 56.998962  413.6469 0.750164367  1.045558 #>  [87,] 36.752348 1358.9528 0.096244016 10.208926 #>  [88,] 17.759547  359.0702 0.195800776  1.992056 #>  [89,] 28.050942  386.0059 0.704414096  8.125418 #>  [90,] 50.636426 1348.7303 0.758286657 10.459714 #>  [91,] 65.817224 1539.3423 0.520428872  7.692900 #>  [92,] 37.150629  611.3058 0.720866849  9.123152 #>  [93,] 94.724637 1388.3405 0.034416246  3.557513 #>  [94,] 36.265905 1452.9045 0.074785546  7.461070 #>  [95,] 26.350127  936.3253 0.094903012  5.481477 #>  [96,] 80.494795 1750.2246 0.335454235  5.947746 #>  [97,] 82.427343  972.1932 0.434686643  4.807200 #>  [98,] 32.209198 1712.5077 0.550839750  5.967153 #>  [99,] 60.744771 1663.7425 0.304251964 10.629160 #> [100,] 20.894404  649.2844 0.761359915  6.672473 #>  #> $y #>   [1] 1.5101065 0.6339769 1.4507384 1.5464959 0.3865964 1.1592724 1.5818320 #>   [8] 0.3947050 1.3817207 1.6254925 1.5725824 0.9872989 1.0355646 1.7049806 #>  [15] 1.4309839 1.5679635 0.5525126 1.5139295 1.4778910 1.6465181 0.7289624 #>  [22] 1.5089291 1.7238282 1.4359739 1.4253358 1.4496450 1.4567138 1.4323466 #>  [29] 1.4276272 1.3876906 1.4681813 1.6227875 1.4251958 0.1053584 1.0972732 #>  [36] 0.8626927 1.2712908 1.2951225 1.3911557 1.1557825 1.5047140 1.5948809 #>  [43] 1.0814238 1.4393496 1.4691991 1.4644084 1.5514881 0.6665826 1.4290911 #>  [50] 0.6043365 1.1916902 1.5913754 1.2944487 1.4660991 1.4679189 1.5692159 #>  [57] 1.5107883 1.1815707 1.2646901 1.3440879 1.4499238 1.4150061 1.6067569 #>  [64] 1.3020876 0.6419686 1.3079808 1.0809698 1.3143271 1.4849533 1.5909111 #>  [71] 1.4404005 1.7683256 1.3997716 1.3411117 1.6532032 1.2466902 0.7338694 #>  [78] 1.1868733 1.5585351 1.3741602 1.7012903 0.1353370 1.5769378 1.3573925 #>  [85] 1.5399638 1.5820420 1.3286977 1.4710865 1.3915036 1.5659549 1.5009938 #>  [92] 1.4126565 0.5985105 1.2690524 1.1962337 1.5087638 1.5508812 1.5844217 #>  [99] 1.4109015 1.3781388 #>"},{"path":"http://merliseclyde.github.io/bark/reference/sim_circle.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate Data from Hyper-Sphere for Classification Problems — sim_circle","title":"Simulate Data from Hyper-Sphere for Classification Problems — sim_circle","text":"classification problem Circle described BARK paper (2008). Inputs dim independent variables uniformly distributed interval \\([-1,1]\\), first 2 dim actually signals. Outputs created according formula $$y = 1(x1^2+x2^2 \\le 2/\\pi)$$","code":""},{"path":"http://merliseclyde.github.io/bark/reference/sim_circle.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate Data from Hyper-Sphere for Classification Problems — sim_circle","text":"","code":"sim_circle(n, dim = 5)"},{"path":"http://merliseclyde.github.io/bark/reference/sim_circle.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate Data from Hyper-Sphere for Classification Problems — sim_circle","text":"n number data points generate dim number dimension problem, less 2","code":""},{"path":"http://merliseclyde.github.io/bark/reference/sim_circle.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate Data from Hyper-Sphere for Classification Problems — sim_circle","text":"Returns list components x input values (independent variables) y 0/1 output values (dependent variable)","code":""},{"path":"http://merliseclyde.github.io/bark/reference/sim_circle.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Simulate Data from Hyper-Sphere for Classification Problems — sim_circle","text":"Ouyang, Zhi (2008) Bayesian Additive Regression Kernels. Duke University. PhD dissertation, Chapter 3.","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/bark/reference/sim_circle.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate Data from Hyper-Sphere for Classification Problems — sim_circle","text":"","code":"sim_circle(n=100, dim=5) #> $x #>                [,1]         [,2]        [,3]          [,4]        [,5] #>   [1,] -0.753849828  0.044161787 -0.41551345 -0.1845852165 -0.98679782 #>   [2,] -0.812749968  0.635493814 -0.41809110 -0.7657177718 -0.55100831 #>   [3,]  0.130080921 -0.605140667  0.97242263 -0.8725806032 -0.34125543 #>   [4,]  0.975956960  0.553862461  0.35956775  0.0976800220  0.13904216 #>   [5,]  0.578395102  0.911328715  0.35560667 -0.3545116619  0.46485778 #>   [6,]  0.223002935 -0.841963086 -0.43834897 -0.7853094498  0.64897128 #>   [7,]  0.364123168 -0.108251631 -0.47488025  0.8403872875 -0.80994858 #>   [8,]  0.178478129  0.261005933 -0.44049132 -0.9984658533  0.46025692 #>   [9,]  0.659961787 -0.263040283 -0.57531402 -0.2250302355  0.97399785 #>  [10,] -0.450548220 -0.997591791 -0.34326271  0.6663312544 -0.50366675 #>  [11,] -0.727019821 -0.758922413  0.87903187 -0.0005424134  0.55305083 #>  [12,]  0.299747780  0.721584757  0.42060824 -0.9376257467  0.65400793 #>  [13,]  0.641611570 -0.794080864  0.36681692  0.6189332251 -0.09292772 #>  [14,]  0.065828737 -0.668824573  0.87132951  0.9982858631 -0.70762081 #>  [15,] -0.300594278 -0.313030266  0.37396710  0.4469967550 -0.41659934 #>  [16,]  0.524626375  0.612795282  0.75762785 -0.3684728779 -0.34038992 #>  [17,]  0.690678331 -0.937050031  0.64924942 -0.2985218680 -0.38740166 #>  [18,]  0.214158744  0.649760266  0.79828222  0.8460070039 -0.73255670 #>  [19,] -0.692494097  0.043684611  0.62264892 -0.4897416360 -0.50180753 #>  [20,]  0.673466758  0.234452296  0.99064333  0.3544681584 -0.23998319 #>  [21,] -0.832450249 -0.558100571  0.84097645  0.7462321362  0.54717977 #>  [22,] -0.669839748 -0.107632620 -0.24882345 -0.2112774365  0.75036350 #>  [23,]  0.370036685 -0.189862621 -0.79359040 -0.4513919801  0.75636372 #>  [24,] -0.602796072  0.799425109 -0.80294706  0.7844434096 -0.31789168 #>  [25,]  0.304673224  0.415587641  0.42637897 -0.4892521631 -0.60640103 #>  [26,]  0.270674882 -0.777146906  0.43460634 -0.9474691781 -0.65106669 #>  [27,]  0.900937285  0.590391591 -0.94134923  0.1476082411  0.25676226 #>  [28,]  0.034450625 -0.778367602  0.03960410 -0.2656162633  0.93349374 #>  [29,] -0.956981108  0.624412060  0.62225174  0.3374757534  0.12547756 #>  [30,]  0.641896528 -0.206326628 -0.69399671 -0.7430123058  0.83818756 #>  [31,]  0.030079482  0.512572926  0.09835880  0.5923477872  0.65872511 #>  [32,] -0.680595271 -0.893745028  0.72430379  0.8986759507  0.20684216 #>  [33,]  0.511070239  0.472732733 -0.67562647 -0.2083882112  0.80211721 #>  [34,] -0.279962411 -0.342248061 -0.96067905  0.1790960324 -0.47101845 #>  [35,]  0.307427207  0.920881989  0.42125083  0.3432982359 -0.83983198 #>  [36,]  0.562002519 -0.663276411  0.36764296  0.1975851981  0.19850330 #>  [37,]  0.930718377 -0.754348148 -0.75260939  0.5496494500  0.83095182 #>  [38,] -0.617358414 -0.051938948  0.73073108 -0.6008825572  0.72628579 #>  [39,]  0.239179984  0.391443789  0.57617645 -0.1610297370  0.79612967 #>  [40,]  0.437392324  0.252979920 -0.36212167  0.8512243740  0.19269649 #>  [41,]  0.001854944 -0.796658118  0.93830464 -0.9094590414 -0.95368864 #>  [42,]  0.023547829 -0.033177441  0.67652331 -0.0741950930  0.02091774 #>  [43,]  0.017969531  0.344759250 -0.11385384 -0.3097533765 -0.94637275 #>  [44,]  0.254127432  0.385273543  0.12474933  0.3574440009 -0.38598117 #>  [45,]  0.380069661  0.954788729 -0.35221758  0.4483178146 -0.90691132 #>  [46,] -0.101762411  0.634150407 -0.84757987  0.0560975610 -0.14867095 #>  [47,] -0.195617525  0.099738319 -0.64241246  0.8257946731 -0.21737337 #>  [48,] -0.926899453  0.986936103  0.62576725 -0.7741410974 -0.16874499 #>  [49,]  0.546756348  0.028321262 -0.41604517 -0.6828317349 -0.18064028 #>  [50,]  0.614999239  0.673827983 -0.54189440  0.0531370668 -0.94215222 #>  [51,] -0.010388093  0.876283143 -0.94833555  0.8941079457  0.51428644 #>  [52,] -0.389683878  0.002653699  0.09703327  0.2749769646  0.53928022 #>  [53,] -0.889491824 -0.987384435 -0.23166470 -0.1024027499  0.76817692 #>  [54,] -0.156292771 -0.552888910  0.42691165 -0.9224653747 -0.29150891 #>  [55,]  0.642329070 -0.954236856  0.89593077 -0.8489854867  0.83007735 #>  [56,]  0.193246397 -0.104384595  0.02534101 -0.7692922871 -0.91051408 #>  [57,] -0.773181595 -0.019717423 -0.44453637 -0.0301440507  0.63542106 #>  [58,] -0.068991744 -0.893029093  0.05050094 -0.5731244590  0.05597063 #>  [59,] -0.552508276  0.210858945 -0.32191617  0.8781461450  0.74586351 #>  [60,]  0.715546057  0.001135941 -0.75039735 -0.5720730810  0.47726677 #>  [61,] -0.510912456  0.392537388  0.03680298 -0.8635691646 -0.39890802 #>  [62,] -0.454356248  0.465259724  0.98298756 -0.1917028707 -0.16107341 #>  [63,]  0.475454241 -0.316243767  0.37247596 -0.2306310600 -0.78031972 #>  [64,]  0.345033772  0.388807089  0.59659341 -0.1982656494  0.05333398 #>  [65,] -0.962489592 -0.584333789  0.94321550  0.3616900789 -0.83929770 #>  [66,] -0.984015703  0.156867405  0.32281071  0.4739046600 -0.51451818 #>  [67,] -0.667472476 -0.454941618 -0.94062761  0.5807208614 -0.80545896 #>  [68,]  0.126059495 -0.786355980 -0.99508853  0.8281530980 -0.49534371 #>  [69,]  0.652318069  0.073784622  0.45144468 -0.9084746605 -0.26581299 #>  [70,]  0.336163447 -0.798528728  0.50908428 -0.1392132444  0.70215638 #>  [71,] -0.557837247  0.550285802 -0.90719735  0.0285660289  0.14129778 #>  [72,] -0.526919291  0.118522769 -0.29919530  0.8035058263 -0.66192816 #>  [73,]  0.093707208  0.768430865 -0.58525269  0.5082988529 -0.65293588 #>  [74,]  0.561984339 -0.788921047  0.07824213  0.3183718529 -0.42304372 #>  [75,] -0.616283384 -0.499071763 -0.77458968 -0.3571467716 -0.15780511 #>  [76,]  0.198646067  0.996793714  0.24104704  0.3403811660 -0.53827011 #>  [77,]  0.854526938  0.490147237 -0.58996248 -0.1281028111 -0.61564884 #>  [78,]  0.799039922  0.415705142 -0.66138977  0.4866837962 -0.38115075 #>  [79,] -0.243774807 -0.920742780 -0.06195412 -0.9526630570 -0.69857154 #>  [80,]  0.931525302 -0.519525132  0.95899116  0.7749334928  0.47519298 #>  [81,]  0.668650641 -0.332115802 -0.40303734  0.7645922317 -0.92488484 #>  [82,] -0.141143296 -0.823521127 -0.70138597  0.2220463110 -0.97885041 #>  [83,] -0.822910749  0.849378454 -0.59401866  0.4978711368  0.05806962 #>  [84,] -0.665299285  0.845453994 -0.18628130  0.7811106308  0.18616323 #>  [85,]  0.831031469  0.333415958 -0.63395262  0.9585460331 -0.20346249 #>  [86,]  0.330811546  0.024566244  0.95963485 -0.1992584672  0.13897403 #>  [87,] -0.490222660  0.492365658 -0.13600129  0.3273299658 -0.89296524 #>  [88,]  0.056171148  0.616835551  0.73017613  0.1931607826  0.56446291 #>  [89,]  0.704292145 -0.139320159 -0.89720289  0.6746348860  0.18161147 #>  [90,]  0.845488121  0.037467274 -0.39994170 -0.2655783389 -0.02849389 #>  [91,]  0.475222867 -0.705550144  0.28661739  0.9887077319  0.70124391 #>  [92,] -0.987170972  0.433464617  0.67237856  0.9914621999 -0.91282848 #>  [93,]  0.009941828  0.430237516  0.81539209  0.4656105428  0.39157798 #>  [94,]  0.021039076  0.356130154 -0.94653623  0.7383182873 -0.37790493 #>  [95,]  0.942632402 -0.132621223  0.32005528  0.2520748652  0.99331406 #>  [96,] -0.097006679 -0.472900466 -0.27042493 -0.9811566146 -0.58090590 #>  [97,]  0.549306822  0.623658898 -0.22187576  0.9589220011  0.11761326 #>  [98,] -0.265587725 -0.895940777  0.79783570 -0.9873871864  0.12729874 #>  [99,]  0.379204390 -0.761267420 -0.48626345 -0.7890875516  0.55550878 #> [100,]  0.433129949 -0.040868045 -0.12059903 -0.1889044801 -0.30597730 #>  #> $y #>   [1] 1 0 1 0 0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 1 1 0 1 0 0 1 0 1 1 0 1 1 0 0 0 #>  [38] 1 1 1 1 1 1 1 0 1 1 0 1 0 0 1 0 1 0 1 1 0 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 0 #>  [75] 1 0 0 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 0 0 0 1 #>"},{"path":[]},{"path":"http://merliseclyde.github.io/bark/news/index.html","id":"major-changes-1-0-5","dir":"Changelog","previous_headings":"","what":"Major Changes","title":"bark 1.0.5","text":"improve computational efficiency saving old log likelihood values rahter recomputing; improve compuational speed close factor 2","code":""},{"path":"http://merliseclyde.github.io/bark/news/index.html","id":"bug-fixes-1-0-5","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"bark 1.0.5","text":"identified error calculation covariance matrix coeffients R/llike.R updated code. (result close large effect)","code":""},{"path":"http://merliseclyde.github.io/bark/news/index.html","id":"bark-104","dir":"Changelog","previous_headings":"","what":"bark 1.0.4","title":"bark 1.0.4","text":"CRAN release: 2023-04-18 archived 3/31 due unit test failure MKL R-devel gcc skip unit test CRAN test code deprecated shortly.","code":""},{"path":"http://merliseclyde.github.io/bark/news/index.html","id":"bark-103","dir":"Changelog","previous_headings":"","what":"bark 1.0.3","title":"bark 1.0.3","text":"failed MKL checks","code":""},{"path":"http://merliseclyde.github.io/bark/news/index.html","id":"bark-103-1","dir":"Changelog","previous_headings":"","what":"bark 1.0.3","title":"bark 1.0.3","text":"failed MKL checks","code":""},{"path":"http://merliseclyde.github.io/bark/news/index.html","id":"bark-101","dir":"Changelog","previous_headings":"","what":"bark 1.0.1","title":"bark 1.0.1","text":"CRAN release: 2023-03-09","code":""},{"path":"http://merliseclyde.github.io/bark/news/index.html","id":"minor-changes-1-0-1","dir":"Changelog","previous_headings":"","what":"minor changes","title":"bark 1.0.1","text":"update longer running examples use \\donttest rather \\dontrun add reference DESCRIPTION","code":""},{"path":[]},{"path":"http://merliseclyde.github.io/bark/news/index.html","id":"major-changes-1-0-0","dir":"Changelog","previous_headings":"","what":"Major Changes","title":"bark 1.0.0","text":"output bark now bark object allow S3 methods replace input arguments y.train x.train use model formula dataframe inputs. replaced argument type two logical variables: selection common_lambdas intuitive. changed running times examples address issue https://CRAN.R-project.org/package=bark led package archived 2015 added registration native routines foreign function calls disabled symbol search src/bark-init.c updated NAMESPACE replaced kernel calculation using .C .Call improve speed src/kernelCalculationCall.cpp R/llike.R added unit tests testthat code coverage reported CI; code coverage badge added README. Unit tests now cover 99% code reported CodeCov added GitHub actions CI checks Windows, MacOSX, Ubuntu added R CMD check passing Badge README.md GitHub repo. converted help files use roxygen tags deprecated functions sim.Circle, sim.Friedman1, sim.Friedman2, sim.Friedman3 created new versions sim_circle, sim_Friedman1, sim_Friedman2, sim_Friedman3 avoid confusion S3 methods updated CODE_OF_CONDUCT.md, SECURITY.md, CONTRIBUTING.md GitHub repo updates OpenSSF BestPractices Badge (added README.md)","code":""},{"path":"http://merliseclyde.github.io/bark/news/index.html","id":"bug-fixes-1-0-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"bark 1.0.0","text":"GitHub Issue #1 Added type checks src/kernelCalculationCall.cpp coerce inputs correct type (unit tests testthat/test-llike.R) reported GitHub Issue #3 Addressed error p = 1 subsetting resulted output vector due drop dimension. Added unit test testthat/test-bark.R","code":""}]
